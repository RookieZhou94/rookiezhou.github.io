<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[极力推荐的博文排版指南]]></title>
    <url>%2F%E6%9E%81%E5%8A%9B%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%9A%E6%96%87%E6%8E%92%E7%89%88%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[作为程序员来说，养成写博客的习惯真的是一件值得去做的事，尽管刚开始可能没有那么高质量的知识输出，但是不是有这样一句话吗？「知识的输入应转化为输出」，也就是说你应该把你所学到的都转化为输出，只有这样你才能更好的掌握你所学的知识，并且在这个过程中你也会对你所学的知识点进行很好的补充。既然要写博文，是不是刚开始就随便写写呢？当然不是，一篇排版好内容不是很好的博文相比于内容好排版很乱的博文能够让人更乐于看下去，尤其是那些对代码有洁癖的程序员我相信你更看不下去，那么以下便是我极力推荐的博客排版指南： 空格的使用「有研究显示，打字的时候不喜欢在中文和英文之间加空格的人，感情路都走得很辛苦，有七成的比例会在 34 岁的时候跟自己不爱的人结婚，而其余三成的人最后只能把遗产留给自己的猫。毕竟爱情跟书写都需要适时地留白。」 中英文之间加空格eg. 相信每个程序员都会去全球最大的同性交友网站 GitHub 上逛逛。 中文和数字之间加空格eg. 那些排版很乱的博文估计你连 1 分钟都看不下去。 数字和单位之间不加空格eg. 现在的安卓手机运行内存没有 6G 都装不了几个应用了。eg. 今天的气温又超过了 40°。eg. 之前买的基金昨天一天跌了 5%。 推荐在链接前后加一个空格eg. 我的公众号和博客名称都是 rookiezhou，搜索 rookiezhou 关注我，点击这里 rookiezhou 访问个人博客。 标点符号的细节 不用为了夸张重复使用标点符号eg. 今年法国夺冠了，华帝刚开始打的一手好牌到最后却变成了一副烂牌，你敢信吗？ 中文段落中尽量使用中文标点符号eg. 一篇好的博文绝对离不开好的排版，所以这篇博文应该算是好文了吧。 推荐将引号换成直角引号eg. 你竟然没看过「Java 编程思想」这本书。 推荐引号中还有引号替换成直角双引号eg. 经常有人带着疑惑的目光对我说「你竟然没看过『Java 编程思想』这本书？」 完整的英文整句使用英文标点符号eg. 引用乔布斯说的那句话：「Stay hungry, stay foolish.」 专有名词大小写尽量规范eg. Java、MySQL 都是后端开发人员必须要会的，当然也要会一些前端的技术，比如说：HTML5、CSS、JavaScript、jQuery。 还有就是对于一些博文可能存在一篇博文下来就只有一段，看起来很紧凑，如果说在每写完一个知识点隔开一行看起来是不是会更好看些呢，这样一来对于我们从小养成的每一段首行空两格的习惯是不是也可以改了呢，其实你去注意一下那些排版比较好的博文，应该大部分都是这么做的，当然这取决于个人，不喜勿喷。 参考： https://www.jianshu.com/p/538faa30b17dhttps://github.com/mzlogin/chinese-copywriting-guidelines]]></content>
      <categories>
        <category>写作</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[正则表达式的基本运用]]></title>
    <url>%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正则表达式，听起来就很高大上，用起来其实挺复杂的，毕竟人家也算是一门语言，但我们在日常开发中如果会一点正则，你会发现有意想不到的效果，对我们开发的效率还是有一定的提高的。刚开始我一直想学习一下一些简单的正则，但每次看完一些资料当时好像明白怎么回事了，但过一段时间没用又忘了，其实说到底就是自己就根本没掌握好，加上又没去实践，当时理解了，长时间不用自然就忘了。所以说学到的知识需要用起来，这样才能加深理解，也不容易忘记。下面主要说一下正则表达式的简单运用，更加高深的正则可能需要花好些时间去系统的学习一番。 测试正则表达式是否正确可以去这个网址，下面的测试都是基于它测试出来的，地址如下： 正则测试 基本匹配这是最简单的正则，也就是平常我们习惯的搜索，根据指定字符去文本中搜索完全匹配的结果。1eg. Regular expressions are a deep language. “dee” ==&gt; Regular expressions are a deep language.“deep” ==&gt; Regular expressions are a deep language. 正则中的元字符 元字符 描述 . 点号匹配任意单个字符除了换行符 [ ] 字符种类，匹配方括号内的任意字符 [^] 否定的字符种类，匹配除了方括号里的字符外其他任意字符 * 量词符号，表示 &gt;= 0,即匹配 &gt;=0 个在 * 号前的字符 + 量词符号，表示 &gt;= 1,即匹配 &gt;=1 个在 + 号前的字符 ? 量词符号，表示 &gt;=0,&lt;=1,即 + 号前的字符可出现可不出现 {n,m} 大括号之前的字符出现 n 到 m 次 (abc) 字符集, 匹配与 xyz 完全相等的字符串 &#124; 或运算符,匹配符号前或后的字符 \ 转义字符,用于匹配一些保留的字符 [ ] ( ) { } . * + ? ^ $ \ &#124; ^ 从文本的头部开始匹配 $ 匹配到文本的结尾 以下面这句话为例，大致说明一下上面表格中的元字符的使用：1eg. Regular expressions are a deep language. 1.匹配 e 字符后面接上任意一个字符，包括空格。 “e.” ==&gt; Regular expressions are a deep language. 2.匹配 e 字符后面接上包含在中括号中的任意一个字符。 “e[g,x,e]” ==&gt; Regular expressions are a deep language. 3.匹配 e 字符后面接上不包含在中括号中的任意一个字符，这里需要注意的是中括号中不能既加上包含字符，又加上不包含的字符，也就是不能这样写：”e[g,^x,^e]” 这样匹配出来的结果和上面匹配的结果一致，如果是把不包含的字符写在前面的话：”e[^g,x,e]” 这样匹配的结果则和下面的结果一致。 “e[^g,^x,^e]” ==&gt; Regular expressions are a deep language. 4.匹配 e 字符后面接上包含中括号中 s 字符任意次，包括 0 次，就是也可以没有字符。 “e[s]*” ==&gt; Regular expressions are a de ep language. 5.匹配 e 字符后面接上包含中括号中 s 字符 1次或多次，就是最少要出现一次。 “e[s]+” ==&gt; Regular expressions are a deep language. 6.匹配 e 字符后面接上包含中括号中 s 字符 0 次或 1 次，就是可有可无，注意和第 4 个的区别。 “e[s]?” ==&gt; Regular expressions are a de ep language. 7.匹配 e 字符后面接上包含中括号中 s 字符指定次数，次数在大括号中指定，可以是一个固定数字，也可以是一个范围。 “e[s]{1}” ==&gt; Regular expressions are a deep language.“e[s]{2,3}” ==&gt; Regular expressions are a deep language. 8.匹配 ee 这个字符集出现 1 次到 2 次。 “(ee){1,2}” ==&gt; Regular expressions are a deep language. 9.匹配 ee 这个字符集出现 1 次到 2 次或者匹配 ss 这个字符集出现 1 次到 2 次。 “(ee){1,2}|ss{1,2}” ==&gt; Regular expressions are a deep language. 10.匹配 e. 这两个字符，注意这里的点号并不是表示任意字符，经过转义后只是单纯的一个点号。 “e\.” ==&gt; Regular expressions are a deep language. 11.下面第一个表示忽略大小写全局匹配 Re 这个两个字符，第二个表示忽略大小写全局匹配以 Re 开头的字符串。 “Re/gi” ==&gt; Regular expressions are a deep language. “^Re/gi” ==&gt; Regular expressions are a deep language. 12.下面第一个表示忽略大小写全局匹配 re 加上任意字符，第二个表示忽略大小写全局匹配以 re 加上任意字符结尾的字符串。 “[r,g]e./gi” ==&gt; Regular expressions are a deep language. “[r,g]e.$/gi” ==&gt; Regular expressions are a deep language. 正则中的简写字符集 简写 描述 . 除换行符外的所有字符 \w 匹配所有字母数字, 等同于 [a-zA-Z0-9_] \W 匹配所有非字母数字, 即符号, 等同于: [^\w] \d 匹配数字: [0-9] \D 匹配非数字: [^\d] \s 匹配所有空格字符, 等同于: [\t\n\f\r\p{Z}] \S 匹配所有非空格字符: [^\s] 前后关联约束1.前置约束存在和前置约束排除：(?=…) 和 (?!…) 通俗点说就是对指定格式的前面的元素进行约束，前者是匹配到的元素后面跟着指定格式，后者是匹配到的元素后面不是跟着指定格式。结合例子可能更好理解：1eg. Regular expressions are a deep language. “ar(?=\s)” ==&gt; Regular expressions are a deep language //匹配 ar 字符串后面跟着的是空格。“ar(?!\s)” ==&gt; Regular expressions are a deep language//匹配 ar 字符串后面跟着的不是空格。 上面两个正则都是对匹配到的 ar 字符串进行约束，前者是跟着的是空格，后者跟着的不是空格；前者约束存在，书写格式为 (?=…)，后者约束不存在，书写格式为 (?!…)。 2.后置约束存在和后置约束排除：(?&lt;=…) 和 (?&lt;!…) 和上面的相对应，对指定格式的后面的元素进行约束，前者是匹配到的元素前面跟着指定格式，后者是匹配到的元素前面不是跟着指定格式。同样结合例子理解：1eg. Regular expressions are a deep language. “(?&lt;=\s)ar” ==&gt; Regular expressions are a deep language //匹配 ar 字符串前面跟着的是空格。“(?&lt;!\s)ar” ==&gt; Regular expressions are a deep language//匹配 ar 字符串前面跟着的不是空格。 上面两个正则同样都是对匹配到的 ar 字符串进行约束，前者的前面要是空格，后者的前面要不是空格，同样的前者约束存在，书写格式为 (?&lt;=…)，后者约束不存在，书写格式为 (?&lt;!…)，相比上面多了个小于号。 标志标志也叫修饰语, 它是用来修改表达式的搜索结果. 这些标志可以任意的组合使用, 它也是正则表达式的一部分，常用的标志有三种：g，i，m，分别表示全局搜索，忽略大小写，多行匹配。 1.全局搜索 g1eg. Regular expressions are a deep language. 匹配测试结果如下： “ar” ==&gt; Regular expressions are a deep language“ar/g” ==&gt; Regular expressions are a deep language 上面两者的区别在于第一个是只搜索匹配到的第一个结果，第二个是全局搜索，将所有匹配的结果全部搜索出来。 2.忽略大小写 i1eg. Regular expressions are a deep language. 匹配测试结果如下： “Reg” ==&gt; Regular expressions are a deep language“REG/i” ==&gt; Regular expressions are a deep language 上面两者的区别在于第一个是只搜索字符完全匹配的结果，第二个是搜索忽略大小写的匹配结果。 3.多行匹配 m123eg. Regular expressions are a deep language,Regular expressions are a deep language,Regular expressions are a deep language. “^Reg/g” 匹配结果如下： Regular expressions are a deep language,Regular expressions are a deep language,Regular expressions are a deep language. “^Reg/gm” 匹配结果如下： Regular expressions are a deep language,Regular expressions are a deep language,Regular expressions are a deep language. 这样一对比两者的区别其实就已经出来了，第一个是全局搜索匹配到的结果，匹配的是第一行的开头，而第二个也是全局搜索匹配到的结果，只不过它是匹配每一行的开头。 以上就是正则表达式的一些基础运用，有了上面的基础，然后在平常开发中积极去尝试写出一些稍微复杂的正则，加强练习，不然只会像我刚开始一样，看完之后过一段时间就忘了，只有不断练习，慢慢的才会对正则有一些感觉。这些正则的基础也是我在 github 上找到一个关于学习正则的项目，然后通过这个项目的学习所掌握的，下面就是这个项目的地址： 学习正则表达式 常用正则表达式123456789101112整数: ^-?\d+$正整数: ^\d+$负整数: ^-\d+$`纯小写字母: ^([a-z])*$纯大写字母: ^([A-Z])*$用户名: ^[\w\d_.]&#123;4,16&#125;$数字和英文字母: ^[a-zA-Z0-9]*$数字和英文字母和空格: ^[a-zA-Z0-9 ]*$密码: ^(?=^.&#123;6,&#125;$)((?=.*[A-Za-z0-9])(?=.*[A-Z])(?=.*[a-z]))^.*$邮箱: ^([a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]&#123;2,4&#125;)*$IP4 地址: ^((?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.)&#123;3&#125;(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))*$URL: ^(((http|https|ftp):\/\/)?([[a-zA-Z0-9]\-\.])+(\.)([[a-zA-Z0-9]])&#123;2,4&#125;([[a-zA-Z0-9]\/+=%&amp;_\.~?\-]*))*$]]></content>
      <categories>
        <category>正则表达式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 单机模式以及伪集群模式搭建]]></title>
    <url>%2Fzookeeper-%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F%E4%BB%A5%E5%8F%8A%E4%BC%AA%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[首先说一下我对 zookeeper 的学习，在刚开始听的时候觉得很高大上，但又觉得很陌生，也不知道是干嘛的，然后就网上查各种资料开始慢慢对 zookeeper 好像有点感觉了，又好像还是似懂非懂的样子，然后还看到网上都在告诉我们 zookeeper 的安装以及 zookeeper 集群的搭建，又尝试着去搭建了一遍。到最后还是有点晕乎乎的样子，总觉得好像不是很理解，包括网上说的 zookeeper 一些使用场景。 通过这些过程下来，我有点觉得刚开始既然不是很理解，那么就先不去理解它，不要尝试着钻牛角尖，为何不先试着在实践中动手接触它，感受它，在这之后有点感觉之后我们再去理解 zookeeper 背后的那些原理会不会更好一点呢？当然这只是个人看法，因人而异，如果有类似感觉的不防这样试试。那么接下来我就先说说 zookeeper 的安装以及搭建过程。 zookeeper 下载解压在测试之前先说一下，zookeeper 的运行需要依赖 Java 运行环境，所以先要保证你安装好了 Java 环境。接下来下载 zookeeper 的最新稳定版 zookeeper-3.4.12 进行测试，下载链接如下： zookeeper-3.4.12 下载链接 由于本人使用的是 Ubuntu 16.04 系统版本，所以下面的测试也是基于该系统下进行测试的，当然在 Window 系统下步骤也是一样的，只是执行的方式不一样而已。将上面下载好的文件进行解压，最好解压到你常用的安装软件目录下，以便后面查找 zookeeper 配置文件的位置，当然如果说你知道你自己所放的位置那也无所谓了，当然我还是比较推荐把我们平常开发中常用的软件单独建一个文件夹保存，这样可以让我们的电脑文件不会显得很乱，后面的查找效率也会高很多。回到正题，下面是 zookeeper 的解压命令： 1tar -xzvf zookeeper-3.4.12.tar.gz -C /home/zhouxh/software/ zookeeper 单机搭建解压好之后，记住你解压之后存放的位置，比如我上面，我存放在 /home/zhouxh/software/ 目录下面，接下来就切到该目录下的 zookeeper-3.4.12 目录下，里面有一个 conf 的目录，继续 cd 到 conf 目录下，这个目录存放的就是 zookeeper 运行时需要的配置文件，这里我们先将里面的 zoo_sample.cfg 文件拷贝一份并且重命名为 zoo.cfg，然后编辑 zoo.cfg 文件，这里我们先不说文件中的各项配置是什么含义，先照着做就可以了，到后面会详细解释，打开 zoo.cfg 文件，在里面修改 dataDir 配置然后再加上 dataLogDir 配置，该文件的全部配置如下：123456789101112131415161718192021222324252627282930# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.#dataDir=/tmp/zookeeperdataDir=/home/zhouxh/software/zookeeper-3.4.12/datadataLogDir=/home/zhouxh/software/zookeeper-3.4.12/logs# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1 上面配置文件中修改和添加的这两项配置都有一个路径，也就是刚才解压的 zookeeper 文件所在路径，在 zookeeper 的目录下创建两个文件夹：data 和 logs，创建好之后单机模式的 zookeeper 文件配置就已经配置好了，然后我们就可以运行了，为了运行方便，最好我们把 zookeeper 命令路径配置到环境变量中去，这样我们就不用每次执行都切换到 zookeeper 目录下的 bin 目录中去，如果没配那就到 zookeeper 的 bin 目录下去执行命令，启动命令如下：1./zkServer.sh start 启动完成之后再执行查看 zookeeper 的运行状态的命令：1./zkServer.sh status 也可以通过客户端命令来连接 zookeeper 服务来判断是否启动成功，如果是 zookeeper 是在本机上那么直接执行以下命令就好： 1./zkCli.sh 如果是跨机器连接的话则需要加参数，-server 后面加上要连的服务 IP 和端口，IP 是你要连的 zookeeper 服务所在机器的 IP，端口就是刚才 zoo.cfg 中的 clientPort=2181 配置的端口。1./zkCli.sh -server 127.0.0.1:2181 连接成功之后我们就可以对 zookeeper 服务上的节点以及节点中的数据进行增删改查了，这里提一下，zookeeper 中的节点结构类似于 Linux 系统下的文件路径，都是树形结构。到这里单机模式的搭建就已经完了，接下来我们再尝试着搭建 zookeeper 伪集群模式。 zookeeper 伪集群搭建有了之前单机模式下搭建过程，伪集群其实也差不多，之所以说是伪集群，是因为是在同一台电脑上模拟出来的多台服务，这里以三台为例进行模拟搭建，当然如果你条件够宽裕，也可以直接在三台电脑上进行搭建，当然这三台电脑需要互相可访问，因为他们之间需要通信。下面是在单台电脑上搭建伪集群的过程： 首先我们将之前用到的 zoo.cfg 拷贝三份放在 conf 目录下，分别命名为 zoo1.cfg，zoo2.cfg，zoo3.cfg，然后分别修改这三个文件，下面我先贴出第一个服务 zoo1.cfg 的配置内容：1234567891011121314151617181920212223242526272829303132# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/home/zhouxh/software/zookeeper-3.4.12/data1dataLogDir=/home/zhouxh/software/zookeeper-3.4.12/log1# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.1=192.168.1.108:2881:3881server.2=192.168.1.108:2882:3882server.3=192.168.1.108:2883:3883 其他两个文件只需要修改其中一个客户端端口和两个路径就好，其他的和上面配置内容一致。zoo2.cfg 不同部分配置内容：1234dataDir=/home/zhouxh/software/zookeeper-3.4.12/data2dataLogDir=/home/zhouxh/software/zookeeper-3.4.12/log2# the port at which the clients will connectclientPort=2182 zoo3.cfg 不同部分配置内容：1234dataDir=/home/zhouxh/software/zookeeper-3.4.12/data3dataLogDir=/home/zhouxh/software/zookeeper-3.4.12/log3# the port at which the clients will connectclientPort=2183 看了上面三个文件的配置内容，我们应该能猜到接下来我们还需要在对应路径下创建几个文件夹，分别是：data1，data2，data3 以及 log1，log2，log3，1234567/home/zhouxh/software/zookeeper-3.4.12/data1/home/zhouxh/software/zookeeper-3.4.12/data2/home/zhouxh/software/zookeeper-3.4.12/data3/home/zhouxh/software/zookeeper-3.4.12/log1/home/zhouxh/software/zookeeper-3.4.12/log2/home/zhouxh/software/zookeeper-3.4.12/log3 同时我们还注意到每个配置文件都多了一小部分内容：123server.1=192.168.1.108:2881:3881server.2=192.168.1.108:2882:3882server.3=192.168.1.108:2883:3883 这部分内容中 server 后面的那个数字是区分各个不同服务的，这个数字还需要在我们刚才新建的那三个文件夹 data1，data2，data3 下面分别新建三个文件，文件名为 myid，这个文件就只写入这个数字就好，也就是 data1 目录下的文件 myid 内容为 1，data2 目录下的文件 myid 内容为 2，data3 目录下的文件 myid 内容为 3，当然如果是三台不同的机器的话，就是把刚才创建三份的文件夹以及文件在每台机器上配置一份就好，内容可以不变，端口那些可以自己定，也可以完全按照上面的方式配置。到这里配置部分就结束了，接下来我们就可以测试我们的配置是否正确了。 首先我们依次将三个 zookeeper 服务分别启动起来，每启动一台查看一下当前启动的 zookeeper 的运行状态，切换到 zookeeper 的 bin 目录下进行启动，启动命令如下：12./zkServer.sh start ~/software/zookeeper-3.4.12/conf/zoo1.cfg./zkServer.sh status ~/software/zookeeper-3.4.12/conf/zoo1.cfg 上面将第一台 zookeeper 服务先启动，启动后紧接着查看其运行状态发现会报如下一个错。 这是由于其他两台还没启动，所以我们先不管，继续启动另外两台服务12345./zkServer.sh start ~/software/zookeeper-3.4.12/conf/zoo2.cfg./zkServer.sh status ~/software/zookeeper-3.4.12/conf/zoo1.cfg./zkServer.sh start ~/software/zookeeper-3.4.12/conf/zoo3.cfg./zkServer.sh status ~/software/zookeeper-3.4.12/conf/zoo3.cfg 不出意外的话，当启动第二台后再查看第一台服务状态时会打印如下信息： 这表明我们已经启动成功了，继续启动第三台就好，当三台全部启动成功后说明我们的伪集群搭建成功了。 我们也可以尝试用 zkCli.sh 命令去连接这个集群看看能不能连上，由于这三台已经是集群模式，我们任意连接其中一台都是一样的，以连接第一台为例： 1./zkCli.sh -server 127.0.0.1:2181 出现如下信息表示连接成功: 上面就是我们搭建的整个过程，搭建完成后最好回顾一下，如果中间遇到什么问题可以直接网上搜索，肯定能找到的，现在我们只是初步了解了 zookeeper 服务的搭建过程，具体这些配置文件中的含义以及为什么要搭建集群，为什么选择三台进行模拟集群，这样做有什么好处；还有就是 zookeeper 到底应该怎么用，哪些情况下需要用到 zookeeper，下一篇将会详细介绍。]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx location 路径匹配规则]]></title>
    <url>%2Fnginx-location-%E8%B7%AF%E5%BE%84%E5%9F%BA%E6%9C%AC%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[之前每次配置 nginx 中的 location 这个路径时都会很头疼，基本上每次都是靠碰运气，一个个去试，直到访问路径通了为止，这样一来到最后还是不知道怎么配置成功的，下次再配置时又需要一个个去试，既浪费时间又很没有效率，所以这次特意花了点时间去学习了一番，特此记录一下，也记录一下自己在测试的过程中踩过的一些坑。 location 匹配模式主要有以下几种匹配模式： = 绝对匹配，如果匹配到了这个将停止匹配并处理该请求 ~ 区分大小写的正则匹配 ~* 不区分大小写的正则匹配 ^~ 如果把这个前缀用于一个常规字符串,那么告诉 nginx 如果路径匹配那么不再去匹配正则 / 通用匹配，任何请求都会匹配到 它们之间的匹配顺序为：1.先匹配普通字符串，然后再匹配正则表达式。2.一般情况下，匹配成功了普通字符串 location 后还会进行正则表达式的 location 匹配。当然有两种方法能够改变这种方式，一个是使用 = 进行绝对匹配，另一个则是使用 ^~ 前缀匹配，它在匹配到了普通字符 location 之后不会再去寻找正则匹配。3.普通字符串匹配顺序是根据配置中的字符长度从长到短，也就是使用普通字符串的匹配顺序和 location 之间的先后顺序是无关的，最后 nginx 都会根据配置的字符长短来进行匹配。4.正则表达式则是按照配置文件里的顺序来匹配，找到第一个匹配的正则表达式将停止搜索。 下面列举常见的几个匹配模式，在测试的过程中注意缓存的原因导致测试结果不正确，优先使用 Firefox 浏览器测试，Chrome 浏览器的缓存更严重。最好的还是每次测试访问时先清除一下缓存，这样才能保证我们的测试结果是正确的。还一个就是注意地址是否填写正确，不要在地址栏最后多出一个斜杠。最后就是我们所编辑的 nginx 配置文件一定要和我们启动的 nginx 配置文件一致。 绝对匹配123location = / &#123; proxy_pass http://192.168.0.234:10080/index;&#125; 上面的绝对匹配只是简单的配置了一个代理，将当前路径代理到另外一个服务的首页。 区分大小写的正则匹配123location ~ image &#123; root /home/zhouxh/;&#125; 上面的配置表示当用户访问 http://192.168.0.234:10080/image/test.jpg 时，将会转到当前服务的 /home/zhouxh/image/ 目录下去查找 test.jpg，也就是 http://192.168.0.234:10080/home/zhouxh/image/test.jpg。 通用匹配123location /image &#123; root /home/zhouxh/;&#125; 由于配置比较简单，上面的配置和上一个正则匹配的结果是一样的，只不过这里是通过普通的匹配方式匹配到 /image 这个 location。 location 中的 root 和 alias 的区别123location /image &#123; root /home/zhouxh/;&#125; 123location /image &#123; alias /home/zhouxh/;&#125; 上面的两个配置当用户访问 http://192.168.0.234:10080/image/test.jpg 时，访问的文件路径是不一样的，当使用 root 时路径为 http://192.168.0.234:10080/home/zhouxh/image/test.jpg，当使用 alias 时路径为 http://192.168.0.234:10080/home/zhouxh/test.jpg，两者的区别在于 root 是将实际访问文件路径即 root 后面的路径拼接 URL 中的路径，而 alias 是实际访问文件路径即 alias 后面的路径不去拼接 URL 中的路径。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx 实现 TCP 代理及其负载均衡之 stream 模块]]></title>
    <url>%2Fnginx-%E5%AE%9E%E7%8E%B0-TCP-%E4%BB%A3%E7%90%86%E5%8F%8A%E5%85%B6%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B9%8B-stream-%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[前面所说的 nginx 负载均衡都是基于 HTTP 七层代理，有时候我们可能需要基于 TCP 四层代理以及负载均衡，在之前我们可能需要编译安装第三方的一个模块 nginx_tcp_proxy_module，并且需要打上一个补丁，具体安装方式可以去参考项目中的描述，项目地址如下，不过需要注意的是安装这个模块存在兼容性问题，最好使用较低版本的 nginx 去安装，否则很容易出错，所以现在不推荐使用这个进行 TCP 代理。在 nginx 1.9.0 的版本以及更高的版本中，nginx 默认将 ngx_stream_core_module 模块编译进来了，该模块支持 TCP 代理及其负载均衡。下面就主要来介绍一下如何使用它来进行 TCP 代理和负载均衡。 nginx_tcp_proxy_module 项目地址 ngx_stream_core_module 编译安装由于 nginx 1.9.0 版本以及之后的版本默认将该模块集成进来了，所以我们不需要额外添加，我们只需要在配置时加上 –with-stream 参数来激活这个模块。命令如下：123sudo ./configure --with-streamsudo makesudo make install TCP 代理将 nginx 配置安装好了之后就可以在 nginx.conf 的配置文件中配置 TCP 代理了，其实也就是在配置文件在加一个和 http 模块平级的 stream 模块，其他配置大部分和 http 代理中的一样，下面是一个简单的 TCP 代理配置：1234567891011121314stream &#123; server &#123; listen 50001; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass 192.168.1.110:10080; &#125; server &#123; listen 50002; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass 192.168.1.111:10080; &#125;&#125; 上面是监听本机的 50001 和 50002 端口，并且将其分别代理到 192.168.1.110 和 192.168.1.111 的 10080 端口，而 10080 这个端口 分别是 192.168.1.110 和 192.168.1.111 的 nginx 访问端口，测试情况如下图： TCP 负载均衡基于 TCP 的负载均衡和 HTTP 的负载均衡配置大致一样，只不过负载均衡策略没有那么多，主要有默认的轮询，加权轮询，最少连接数，最低平均延时，hash 这五种方式，先声明以下测试是在 nginx 版本 1.12.0 上测试的。这里简单说一下我所遇到的坑，我刚开始是在 chrome 浏览器上测试的，发现测试这些策略都是不对的，而且始终访问到后台同一台服务，只是偶尔会变一下，然后使用 Firefox 浏览器测试，发现按 F5 刷新还是始终访问到同一后台服务，然后尝试着按 Ctrl + F5 进行刷新这才按照我们配置的策略进行负载，而回到 chrome 浏览器上也试着按 Ctrl + F5 刷新还是一直访问的后台同一台服务，暂时还不知道是什么原因。有知道的可以告诉我一下，不甚感激。 1.默认配置 ( 轮询 ) 12345678910stream &#123; upstream loadserver &#123; server 192.168.1.110:10080; server 192.168.1.111:10080; &#125; server &#123; listen 8000; # 需要监听的端口 proxy_pass loadserver; &#125;&#125; 上面的配置就是不加任何负载策略，采用默认的方式，默认的方式就是轮询的方式。 2.加权轮询配置12345678910stream &#123; upstream loadserver &#123; server 192.168.1.110:10080 weight=3; server 192.168.1.111:10080; &#125; server &#123; listen 8000; # 需要监听的端口 proxy_pass loadserver; &#125;&#125; 这是在轮询策略的基础上给每个后台服务加上权重，权重越大，访问的概率越大，像上面的配置的话就是每访问三次 192.168.1.110 这台服务就会访问一次 192.168.1.111 这台服务。 3.最少连接数配置 1234567891011stream &#123; upstream loadserver &#123; least_conn; server 192.168.1.110:10080; server 192.168.1.111:10080; &#125; server &#123; listen 8000; # 需要监听的端口 proxy_pass loadserver; &#125;&#125; 上面是采用一种固定的负载策略，最少连接数策略，也就是选择连接数最少的后台服务。 4.最低平均延时配置 12345678910111213stream &#123; upstream loadserver &#123; least_time connect; #least_time first_byte; #least_time last_byte; server 192.168.1.110:10080; server 192.168.1.111:10080; &#125; server &#123; listen 8000; # 需要监听的端口 proxy_pass loadserver; &#125;&#125; 上面策略配置表示的是对于每个请求，可通过最低平均延时来选择后台服务，而这个最低平均延时则是看 least_time 指令中指定的参数计算出来的，主要有下面三个参数： connect：连接到后台服务花的时间 first_byte：接收到第一个字节花的时间 last_byte：接收到最后一个字节花的时间，也就是全部接收完的时间 值得注意的是该策略现在是作为 nginx 商业订阅的一部分提供，也就是需要花钱才能够实现这个功能。 5.hash 配置 1234567891011stream &#123; upstream loadserver &#123; hash $remote_addr consistent; server 192.168.1.110:10080; server 192.168.1.111:10080; &#125; server &#123; listen 8000; # 需要监听的端口 proxy_pass loadserver; &#125;&#125; 上面采用的是 hash 算法策略，对客户端的 IP 进行 hash，让每台客户端固定访问到后台的一台服务。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx 负载均衡策略之第三方扩展策略]]></title>
    <url>%2Fnginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5%E4%B9%8B%E7%AC%AC%E4%B8%89%E6%96%B9%E6%89%A9%E5%B1%95%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[之前已经将 nginx 负载均衡中的内置策略介绍完了，下面我们来看一下第三方的扩展策略，所谓的内置策略其实就是 nginx 安装后就已经自带了，对于第三方的一些策略则是需要我们在安装时要额外添加第三方的模块才能实现。下面就一一进行介绍： url_hash该策略将前端请求的 url 地址进行 hash，根据 hash 结果将请求定向到同一后端服务器节点上，这种适合后台服务器为缓存时比较有效，一般也会配合缓冲命中来使用。 刚才也说了第三方策略需要额外添加第三方模块才能实现，所以我们需要对我们的 nginx 进行重新编译安装，下面是添加第三方模块编译安装的命令，但要注意的是这个第三方模块需要我们提前下载好，下面命令中的路径就是我下载的模块所在路径。url_hash 策略需要的第三方模块是 ngx_http_consistent_hash，这个可以在 nginx 第三方模块网站中找到该项目的 github 地址，这里贴出地址： nginx 第三方模块网站ngx_http_consistent_hash 项目地址 123sudo ./configure --add-module=/home/zhouxh/software/ngx_http_consistent_hashsudo makesudo make install 然后还是在之前我们添加的 upstream 中加上对应的策略，配置如下，不清楚的可以参考上一篇的内容。12345upstream loadserver &#123; consistent_hash $request_uri; server 192.168.1.110:10080; server 192.168.1.111:10080;&#125; 上面的配置加了一个调度策略：一致性哈希 consistent_hash，对客户端请求的 url 进行哈希，既然这里采用 url_hash 的策略来进行负载，那么对于后面再进行权重配置就没有多大意义了，所以后面就不必再添加 weight 权重配置了。 fair这个策略按后端服务器的响应时间来分配请求，响应时间短的优先分配，但在实际项目中，响应时间受很多的因素所影响，所以真正采用这种方式进行负载需慎重。同样的先下载 fair 策略对应的第三方模块 nginx-upstream-fair，再对我们的 nginx 进行重新编译安装，nginx-upstream-fair 项目地址如下： nginx-upstream-fair 项目地址 这个项目其实并不是第三方模块网站中找到的那个 nginx-upstream-fair 项目，那个项目我使用 nginx-1.12.0 版本的 nginx 编译出错，于是看到那个项目中也有人遇到这个问题，他推荐的是另一个 nginx-upstream-fair 项目，也就是上面贴出来的那个，编译正常通过，基于 nginx-1.12.0 版本的 nginx 亲测可用。编译安装命令如下：123sudo ./configure --add-module=/home/zhouxh/software/ngx_http_consistent_hash --add-module=/home/zhouxh/software/nginx-upstream-fairsudo makesudo make install 配置也是一样的，只是需要改变一下策略名称： 12345upstream loadserver &#123; fair; server 192.168.1.110:10080; server 192.168.1.111:10080;&#125; sticky该策略是在多台服务器的环境下，确保一个客户端只和一台服务器通讯，它会保持长连接，并在结束会话后再次选择一个服务器，保证了压力均衡。同样的我们先下载 fair 策略对应的第三方模块 nginx-upstream-fair，再对我们的 nginx 进行重新编译安装，nginx-upstream-fair 模块在第三方模块网站中能够找到直接下载： nginx 第三方模块网站 编译安装命令如下：123sudo ./configure --add-module=/home/zhouxh/software/ngx_http_consistent_hash --add-module=/home/zhouxh/software/nginx-upstream-fair --add-module=/home/zhouxh/software/nginx-sticky-module-ngsudo makesudo make install 配置也是一样的，需要改变一下策略名称： 12345upstream loadserver &#123; sticky; server 192.168.1.110:10080; server 192.168.1.111:10080;&#125; 注意：由于整个模块是通过 cookie 实现，如果浏览器不支持 cookie，那么 sticky 不生效。 到这里 nginx 负载均衡一些扩展的第三方策略也全部介绍完了 ，有点要提醒的是以上都是基于 HTTP 七层负载均衡，还有一个是 TCP 四层负载均衡，接下来会有介绍。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx 负载均衡策略之内置策略]]></title>
    <url>%2Fnginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5%E4%B9%8B%E5%86%85%E7%BD%AE%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[nginx 服务器在开发中我们用的比较多的有 nginx 的负载均衡，nginx 负载均衡主要是利用反向代理来实现，也就是表面上我们访问的是这个服务，其实访问的是该服务背后支撑的众多服务器中的其中一台。比如说全世界同一时间有这么多人同时在访问百度这个网站，它是怎么能够承受的住这么大的访问量呢，这时我们就应该知道其实百度这个网站的背后有很多的服务器在支撑着众多的用户的访问。但是这里就引出一个问题，用户访问的这个服务是如何分发给它背后的众多的服务器呢，于是就出现了满足各种需求的负载均衡策略，其中有 nginx 自己内置的负载均衡策略，也有第三方提供的一些负载均衡策略。今天主要谈一下 nginx 内置的负载均衡策略，主要有四种：轮询（默认）、加权轮询、最少连接 least_conn、IP 哈希 ip_hash，下面将一一进行介绍。 首先我们先安装好 nginx 服务器，下面是在 Ubuntu 16.04 系统测试的，采用的 nginx 版本是 nginx/1.12.0。 安装 nginx下载基于 Linux 系统的 nginx/1.12.0 版的 nginx 服务器进行解压编译安装，下面是安装命令。 123456sudo wget http://nginx.org/download/nginx-1.12.0.tar.gzsudo tar xzf nginx-1.12.0.tar.gzcd nginx-1.12.0sudo ./configuresudo makesudo make install 上面安装成功后，nginx 默认安装在目录 /usr/local/nginx/ 下面，当然你也可以自定义安装目录，不过一般不建议这么做，以防以后都不知道到哪里去找配置文件，默认就好，安装成功后可以在 /usr/sbin/ 目录下创建一个软链接指向 /usr/local/nginx/sbin/nginx 文件，命令如下： 1ln -s /usr/sbin/nginx /usr/local/nginx/sbin/nginx 这样我们就不用每次启动 nginx 服务都切换到 /usr/local/nginx/sbin/ 目录下去执行 nginx 的启动命令，配置好了这些后就可以启动 nginx 服务器进行测试了。 1sudo nginx -c /usr/local/nginx/conf/nginx.conf 执行上面的启动命令后在浏览器中输入 localhost 后回车出现对应的 nginx 服务器的欢迎页面就表示 nginx 服务器安装成功了，这里我们为了更好的测试首先将 nginx.conf 配置文件中 http 的默认端口 80 改成 10080，改了之后重新启动 nginx 服务器后接着在浏览器中输入 localhost:10080 后回车应该又会出现刚才的欢迎页面了。接下来就开始我们的 nginx 的负载均衡策略之旅吧。 轮询（默认）轮询这个策略是 nginx 进行负载均衡时默认采用的策略，也就是最基本的负载均衡配置，打开 /usr/local/nginx/conf/ 目录下的 nginx.conf 配置文件，我们配置一个最简单的负载均衡方式，在配置文件中 http 模块里面也就是和 http 模块里面的 server 模块同级加上以下内容： 1234upstream loadserver &#123; server 192.168.1.110:10080; server 192.168.1.111:10080;&#125; 然后在 http 模块里面的 server 模块下面的 location 模块加上一行配置，如下： 12345location / &#123; root html; index index.html index.htm; proxy_pass http://loadserver;&#125; 部分配置文件截图如下： 这样也就配置好了最基本的负载均衡，默认采用轮询的策略将请求分发给后台服务器，当我们访问 localhost:10080 这个地址时页面轮流的展示 192.168.1.110 和 192.168.1.111 这两台主机的 nginx 服务器的欢迎页面，这里为了区分这两个欢迎页面需要修改一下这两台主机的 nginx 服务器的欢迎页面信息，欢迎页面默认存放在 /usr/local/nginx/html/ 目录下的 index.html 页面。我们只要稍微修改一下这两台主机的 nginx 欢迎页面使得每次访问的页面都是不同的，便于我们区分访问的是哪台主机的 nginx 服务器。 加权轮询加权轮询则是在第一种轮询的基础上对后台的每台服务赋予权重，服务器的权重比例越大，被分发到的概率也就越大，配置如下： 1234upstream loadserver &#123; server 192.168.1.110:10080 weight=3; server 192.168.1.111:10080 weight=1;&#125; 上面只是给每个后台服务加上了一个权重比例，拿上面的配置举例：用户将会每访问三次 192.168.1.110 这个服务访问一次 192.168.1.111 这个服务。这种适合后台的各个服务的性能不一样，这时我们就可以将性能好的服务器权重设置大一些，减轻一些性能不怎么样的服务器的压力。 最少连接 least_conn最少连接是每次请求都将请求分发给后台服务连接数最少的那台服务上，当然如果每台服务还配置了权重，那么这时会取连接数和权重比值最小的那台服务，如果连接数和权重的比值都相同的话就会采取轮询的方式进行分发，配置如下： 12345upstream loadserver &#123; least_conn; server 192.168.1.110:10080; server 192.168.1.111:10080;&#125; 上面的配置只是加了一个调度策略 least_conn，其他和轮询的方式一样，当然你也可以给每台服务加上权重比例，分发时就会选择 conn / weight 值最小的那台服务，这种方式适合请求处理时间长短不一造成服务器过载的情况。 IP 哈希 ip_haship_hash 这种负载策略是根据客户端的 IP 地址的 hash 结果来进行分发，这样的话能够确保每个访客访问后端固定的一台服务器，这种情况对于需要保存用户的 session 信息的应用就很方便了，它避免了同一个用户访问到不同的服务器上产生 session 共享的问题。配置如下： 12345upstream loadserver &#123; ip_hash; server 192.168.1.110:10080; server 192.168.1.111:10080;&#125; 上面的配置只是加了一个调度策略 ip_hash，其他也和轮询的方式一样，这里你也可以给每台服务加上权重比例，分发时在该客户端 IP 第一次访问时就会优先选择 weight 值最大的那台服务。 其他配置说明其实每个后台服务器的配置除了权重 weight 还有一些配置，比如说下面的配置：12345678upstream loadserver &#123; least_conn; server 192.168.1.110:10080 weight=5 ; server 192.168.1.111:10080 weight=1; server 192.168.1.112:10080 weight=1 max_fails=3 fail_timeout=30s; server 192.168.1.113:10080 down; server 192.168.1.114:10080 backup;&#125; 配置说明：1.weight 的值默认为1，weight 越大，服务器负载的权重就越大，访问的概率越高。2.down 表示当前服务器暂时不参与负载。3.backup 表示其它所有的非 backup 服务器 down 或者忙的时候才会请求 backup 服务器，所以这台服务器压力最轻，一般这台服务器当做是备用服务器。3.max_fails 表示允许请求失败的次数，默认为 1，当超过最大次数时，返回proxy_next_upstream 模块定义错误。4.fail_timeout 表示每次失败后暂停的时间。 到这里就全部介绍完了 nginx 负载均衡内置的一些策略，还有第三方扩展的一些策略，未完待续………]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx 的正向代理和反向代理]]></title>
    <url>%2Fnginx-%E7%9A%84%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E5%92%8C%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[nginx 服务器在我们平常的软件开发中可能还是用到的比较多的，那么有一个问题我们就应该明白，也许让你去实现轻而易举，但说到其中的原理就有点不是很清楚了。下面就谈谈我自己对正向代理和反向代理的理解：首先有一个用户 C，三台服务器 S1，S2 和 S3，S1，S2，S3 在同一局域网内互相可访问，但 S1 对外网开放，S2 和 S3 不对外网开放，还有一份数据资源 D，资源 D 放在服务器 S2 和 S3 上。 nginx 正向代理这时用户 C 明确知道自己想访问的数据资源 D 在服务器 S2 上，用户 C 想要访问这份资源但是没办法直接访问服务器 S2，用户 C 想到服务器 S1 和 S2 在同一局域网并且互相可访问，而自己能够访问服务器 S1，所以用户 C 就通过服务器 S1 去访问服务器 S2 上的资源 D。那么正向代理就是对于用户 C 来说他是明确知道他要访问的数据资源 D 在哪个服务器上；对于服务器 S1 来说他只充当了用户 C 的中间代理角色；而对于服务器 S2 来说他只知道访问他的资源的是服务器 S1，根本不知道用户 C 的存在。 正向代理的整个流程就是用户 C 访问服务器 S2 上的数据资源 D，但是是通过借助服务器 S1 来进行访问，服务器 S1 得到数据资源后再返回给用户 C。 nginx 反向代理还是刚开始上面说的这些：用户 C，服务器 S1，S2 和 S3，以及服务器 S2 和 S3 上的数据资源 D。这时用户 C 并不知道数据资源 D 在服务器 S2 和 S3 上面，他只知道访问服务器 S1 可以得到自己想要的内容，于是他每次都是直接访问服务器 S1，只不过提供给用户 C 数据资源的都是服务器 S2 或者 S3。那么反向代理就是对于用户 C 来说他是不知道数据资源 D 具体在哪里，是由谁提供的；对于服务器 S1 来说每次都接收用户的请求，然后再把请求交给真正能提供资源的服务器 S2 或 S3；对于服务器 S2 和 S3 来说同样也都不知道访问这份资源的真实用户是谁，只是和服务器 S1 进行交互。 反向代理的整个流程就是用户 C 访问服务器 S1 获取数据资源 D，服务器 S1 将请求转交给服务器 S2 或 S3，然后得到相应的资源后再返回给用户 C。 总之，正向代理就是客户端知道服务器端，带过代理连接服务器端。反向代理就是客户端不知道服务器端，通过代理连接服务器端，具体是由哪个服务器端提供服务取决于代理的调度方式，即 nginx 中的负载均衡策略。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java 8 特性--Stream 流]]></title>
    <url>%2FJava-8-%E7%89%B9%E6%80%A7-Stream-%E6%B5%81%2F</url>
    <content type="text"><![CDATA[Java 8 API 添加了一个新的抽象称为流 Stream，可以让你以一种声明的方式处理数据，Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。Stream API 可以极大提高 Java 程序员的生产力，让程序员写出高效率、干净、简洁的代码。这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation) 得到前面处理的结果。 Stream 的定义Stream（流）是一个来自数据源的元素队列并支持聚合操作，元素是特定类型的对象，形成一个队列。 Java 中的 Stream 并不会存储元素，而是按需计算。 数据源：流的来源。 可以是集合，数组，I/O channel， 产生器generator 等。 聚合操作：类似SQL语句一样的操作， 比如filter, map, reduce, find, match, sorted等。 和以前的 Collection 操作不同， Stream 操作还有两个基础的特征： Pipelining: 中间操作都会返回流对象本身。这样多个操作可以串联成一个管道， 如同流式风格（fluent style）。 这样做可以对操作进行优化， 比如延迟执行 (laziness) 和短路 (short-circuiting)。 内部迭代： 以前对集合遍历都是通过 Iterator 或者 For-Each 的方式, 显式的在集合外部进行迭代， 这叫做外部迭代。 Stream提供了内部迭代的方式， 通过访问者模式 (Visitor) 实现。 在 Java 8 中，集合接口有两个方法生成流： stream() − 为集合创建串行流。 parallelStream() − 为集合创建并行流。 过滤123456789101112List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList());System.out.println(&quot;筛选后的列表: &quot; + filtered);// 统计空字符串数量long count = strings.stream().filter(String::isEmpty).count();System.out.println(&quot;空字符串数量为: &quot; + count);// 流并行处理count = strings.parallelStream().filter(String::isEmpty).count();// 将字符串不为空的筛选出来并且以逗号分隔合并起来String mergedString = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.joining(&quot;, &quot;));System.out.println(&quot;合并字符串: &quot; + mergedString); map 映射1234List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);// 求各元素的平方List&lt;Integer&gt; squaresList = numbers.stream().map(i -&gt; i * i).distinct().collect(Collectors.toList());System.out.println(&quot;Squares List: &quot; + squaresList); 统计123456List&lt;Integer&gt; integers = Arrays.asList(1, 2, 13, 4, 15, 6, 17, 8, 19);IntSummaryStatistics stats = integers.stream().mapToInt((x) -&gt; x).summaryStatistics();System.out.println(&quot;列表中最大的数 : &quot; + stats.getMax());System.out.println(&quot;列表中最小的数 : &quot; + stats.getMin());System.out.println(&quot;所有数之和 : &quot; + stats.getSum());System.out.println(&quot;平均数 : &quot; + stats.getAverage()); 分组123456789// 根据景区等级分组List&lt;Scenic&gt; scenicList = new ArrayList&lt;&gt;();scenicList.add(new Scenic(1L, &quot;西湖&quot;, 5));scenicList.add(new Scenic(2L, &quot;千岛湖&quot;, 5));scenicList.add(new Scenic(3L, &quot;乌镇&quot;, 4));scenicList.add(new Scenic(4L, &quot;雷峰塔&quot;, 3));scenicList.add(new Scenic(4L, &quot;灵隐寺&quot;, 4));Map&lt;Integer, List&lt;Scenic&gt;&gt; mapGroup = scenicList.stream().collect(Collectors.groupingBy(Scenic::getScenicLevel));System.out.println(mapGroup); 转成 Map123456789/*** toMap 如果集合对象有重复的key，会报错Duplicate key ....*///Map&lt;Long, Scenic&gt; scenicMap = scenicList.stream().collect(Collectors.toMap(Scenic::getId, a -&gt; a));//System.out.println(scenicMap);// 可以用 (k1,k2)-&gt;k1 来设置，如果有重复的 key,则保留 key1,舍弃 key2Map&lt;Long, Scenic&gt; scenicMap = scenicList.stream().collect(Collectors.toMap(Scenic::getId, a -&gt; a, (k1, k2) -&gt; k1));System.out.println(scenicMap); reduce sum 求和123456789101112List&lt;Integer&gt; integers = Arrays.asList(1, 2, 3, 4, 5);// 没有起始值时返回为Optional类型Optional&lt;Integer&gt; sumOptional = integers.stream().reduce(Integer::sum);System.out.println(sumOptional.get());// 可以给一个起始种子值Integer sumReduce = integers.stream().reduce(0, Integer::sum);System.out.println(sumReduce);//直接用sum方法Integer sum = integers.stream().mapToInt(i -&gt; i).sum();System.out.println(sum); 根据某个属性求平均数123// 等级平均数OptionalDouble average = scenicList.stream().mapToInt(Scenic :: getScenicLevel).average();System.out.println(average.getAsDouble());]]></content>
      <categories>
        <category>Java 8</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java 8 特性--Optional 类、时间 API 以及 Base64 编解码]]></title>
    <url>%2FJava-8-%E7%89%B9%E6%80%A7-Optional-%E7%B1%BB%E3%80%81%E6%97%B6%E9%97%B4-API-%E4%BB%A5%E5%8F%8A-Base64-%E7%BC%96%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Optional 类Optional 类是一个可以为 null 的容器对象，可以保存类型 T 的值，或者仅仅保存 null，它提供很多有用的方法，让我们不用再显式的进行空值检测，Optional 类的引入很好的避免了发生空指针异常，下面我们看一个简单的例子：12345678910111213141516171819Integer value1 = null;Integer value2 = 10;// Optional.ofNullable - 允许传递为 null 参数Optional&lt;Integer&gt; optional1 = Optional.ofNullable(value1);// Optional.of - 如果传递的参数是 null，抛出异常 NullPointerExceptionOptional&lt;Integer&gt; optional2 = Optional.of(value2);System.out.println(&quot;第一个参数值是否存在: &quot; + optional1.isPresent());System.out.println(&quot;第二个参数值是否存在: &quot; + optional2.isPresent());// Optional.orElse - 如果值存在，返回它，否则返回默认值Integer result1 = optional1.orElse(0);System.out.println(result1);//Optional.get - 获取值，值需要存在Integer result2 = optional2.orElse(0);System.out.println(result2); Java 8 日期时间 API在 Java 8 以前，我们都知道 Java 中的时间处理很繁琐，有时候还会去纠结我到底是用 java.util 包下的日期还是 java.sql 包下的日期呢。因此往往在遇到时间处理问题时都会借助于框架来实现，比如 Joda-Time。但在 Java 8 中也增加了同样的类似框架功能的时间处理 API，下面列出一些简单的例子： 12345//Clock 类使用时区来返回当前的毫秒数和日期。Clock 可以替代System.currentTimeMillis() 和 TimeZone.getDefault()。 Clock clock = Clock.systemUTC();System.out.println(clock.millis());System.out.println(System.currentTimeMillis()); 123456789101112131415161718192021222324252627282930313233343536373839// 获取当前日期LocalDate currentDate = LocalDate.now();System.out.println(&quot;当前日期: &quot; + currentDate);// 获取当前时间LocalTime currentTime = LocalTime.now();System.out.println(&quot;当前时间: &quot; + currentTime);// 获取当前日期时间LocalDateTime currentDateTime = LocalDateTime.now();System.out.println(&quot;当前日期时间: &quot; + currentDateTime);// 根据当前日期时间获取当前日期LocalDate currentDate1 = currentDateTime.toLocalDate();System.out.println(&quot;currentDate1: &quot; + currentDate1);// 根据当前日期时间获取当前时间LocalTime currentTime1 = currentDateTime.toLocalTime();System.out.println(&quot;currentTime1: &quot; + currentTime1);Month month = currentDateTime.getMonth();int day = currentDateTime.getDayOfMonth();int seconds = currentDateTime.getSecond();System.out.println(&quot;月: &quot; + month +&quot;, 日: &quot; + day +&quot;, 秒: &quot; + seconds);// 指定日期LocalDateTime date2 = currentDateTime.withDayOfMonth(10).withYear(2012);System.out.println(&quot;date2: &quot; + date2);// 12 december 2014LocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 12);System.out.println(&quot;date3: &quot; + date3);// 22 小时 15 分钟LocalTime date4 = LocalTime.of(22, 15);System.out.println(&quot;date4: &quot; + date4);// 解析字符串LocalTime date5 = LocalTime.parse(&quot;20:15:30&quot;);System.out.println(&quot;date5: &quot; + date5);// 获取当前日期时间的另一个时区的日期时间System.out.println(currentDateTime.atZone(ZoneId.of(&quot;America/New_York&quot;))); 12345LocalDateTime from = LocalDateTime.of( 2017, Month.MAY, 16, 0, 0, 0 );LocalDateTime to = LocalDateTime.of( 2018, Month.MAY, 16, 23, 59, 59 );Duration duration = Duration.between( from, to );System.out.println( &quot;Duration in days: &quot; + duration.toDays() );System.out.println( &quot;Duration in hours: &quot; + duration.toHours()); 上面只是列举了一些简单的东西，其实还有一些，比如时间的加减运算，这些在用到时可以根据提示来进行我们想要的操作。 Java8 Base64Java 8 内置了 Base64 编码的编码器和解码器，并且 Base64 工具类提供了一套静态方法获取下面三种 BASE64 编解码器： 基本：输出被映射到一组字符 A-Za-z0-9+/，编码不添加任何行标，输出的解码仅支持 A-Za-z0-9+/。 URL：输出映射到一组字符A-Za-z0-9+_，输出是 URL 和文件。 MIME：输出映射到 MIME 友好格式，输出每行不超过 76 字符，并且使用 ‘\r’ 并跟随 ‘\n’ 作为分割，编码输出最后没有行分割。 下面也是一个简单的例子展示了如何获取这三种编解码器：12345678910111213141516171819202122// 基本编码String base64encodedString = Base64.getEncoder().encodeToString(&quot;java 8&quot;.getBytes(&quot;utf-8&quot;));System.out.println(&quot;Base64 编码字符串 (基本) :&quot; + base64encodedString);// 基本解码byte[] base64decodedBytes = Base64.getDecoder().decode(base64encodedString);System.out.println(&quot;原始字符串: &quot; + new String(base64decodedBytes, &quot;utf-8&quot;));// URL 编码base64encodedString = Base64.getUrlEncoder().encodeToString(&quot;url?java8&quot;.getBytes(&quot;utf-8&quot;));System.out.println(&quot;Base64 编码字符串 (URL) :&quot; + base64encodedString);// URL 解码byte[] base64decodedBytesUrl = Base64.getUrlDecoder().decode(base64encodedString);System.out.println(&quot;原始字符串: &quot; + new String(base64decodedBytesUrl, &quot;utf-8&quot;));StringBuilder stringBuilder = new StringBuilder();for (int i = 0; i &lt; 10; ++i) &#123; stringBuilder.append(UUID.randomUUID().toString());&#125;byte[] mimeBytes = stringBuilder.toString().getBytes(&quot;utf-8&quot;);// MINE 编码String mimeEncodedString = Base64.getMimeEncoder().encodeToString(mimeBytes);System.out.println(&quot;Base64 编码字符串 (MIME) :&quot; + mimeEncodedString);]]></content>
      <categories>
        <category>Java 8</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java 8 特性--Lambda 表达式、接口默认方法以及方法引用]]></title>
    <url>%2FJava-8-%E7%89%B9%E6%80%A7-Lambda-%E8%A1%A8%E8%BE%BE%E5%BC%8F%E3%80%81%E6%8E%A5%E5%8F%A3%E9%BB%98%E8%AE%A4%E6%96%B9%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Java 8 (又称为 jdk 1.8) 是 Java 语言开发的一个主要版本，Java 8 增加了许多的新特性，在此先记录一下 Lambda 表达式，接口默认方法和方法引用这三个特性。 Lambda 表达式Lambda 表达式，也可称为闭包，允许把函数作为一个方法的参数（函数作为参数传递进方法中），使用 Lambda 表达式可以使代码变的更加简洁紧凑。语法格式：1(parameters) -&gt; expression 或 (parameters) -&gt;&#123; statements; &#125; 主要特征： 可选类型声明，不需要声明参数类型，编译器可以统一识别参数值。 可选的参数圆括号，一个参数无需定义圆括号，但多个参数需要定义圆括号。 可选的大括号，如果主体只包含一个语句，就不需要使用大括号。 可选的返回关键字，如果主体只有一个表达式返回值则编译器会自动返回值，大括号的话需要指明表达式返回了一个数值。 下面通过一些小例子来展示，首先先定义两个函数式接口：123interface MathOperation &#123; int operate(int a, int b);&#125; 123interface Greeting &#123; void sayMessage(String greeting);&#125; 创建一个测试类，通过 main 方法来进行测试，代码中有详细注释12345678910111213141516171819202122232425262728293031public static void main(String[] args) &#123; Java8 java8 = new Java8(); //参数类型可声明可不声明 MathOperation addition = (int a, int b) -&gt; a + b; MathOperation subtraction = (a, b) -&gt; a - b; //可选的参数圆括号 Greeting greeting = message -&gt; System.out.println(&quot;hello &quot; + message); Greeting greeting1 = (message) -&gt; System.out.println(&quot;hello &quot; + message); greeting.sayMessage(&quot;Tom&quot;); greeting1.sayMessage(&quot;Jim&quot;); //可选的大括号以及可选的返回关键字，当有大括号时返回值需指定 return 语句 MathOperation multiplication = (int a, int b) -&gt; &#123; return a * b; &#125;; MathOperation division = (a, b) -&gt; a / b; //测试执行输出，将上面定义的函数传进 operate 方法中 System.out.println(java8.operate(1, 2, addition)); //上面的另一种写法 System.out.println(addition.operate(1, 2)); System.out.println(java8.operate(1, 2, subtraction)); System.out.println(java8.operate(1, 2, multiplication)); System.out.println(java8.operate(1, 2, division)); System.out.println(java8.operate(1,2, (a, b) -&gt; a + b));&#125;private int operate(int a, int b, MathOperation mathOperation) &#123; return mathOperation.operate(a, b);&#125; 接口默认方法默认方法就是接口可以有实现方法，而且不需要实现类去实现这个默认方法，定义时我们只需在方法名前面加个 default 关键字即可实现默认方法。 至于为什么会产生这个特性？首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是当需要修改接口时候，需要修改它的全部实现类，目前 java 8之前的集合框架没有 foreach 方法，通常能想到的解决办法是在 JDK 里给相关的接口添加新的方法定义及给相应实现类添加实现，然而对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现，所以才引进的默认方法。目的就是为了解决接口的修改与现有的实现不兼容的问题。 下面是接口默认方法和接口静态默认方法的基本实现：1234567891011interface Action1 &#123; //默认方法 default void eat() &#123; System.out.println(&quot;吃东西1&quot;); &#125; //静态默认方法 static void fun() &#123; System.out.println(&quot;玩&quot;); &#125; void call();&#125; 12345interface Action2 &#123; default void eat() &#123; System.out.println(&quot;吃东西2&quot;); &#125;&#125; 这里接口 Action1 和 Action2 都有 eat 这个相同的默认方法，当一个实现类同时实现了这个两个接口时就需要实现类显式的覆盖两个接口中相同的 eat 方法，至于实现类中如何重写 eat 方法取决于实现类，实现类既可以完完全全由自己重写，也可以使用 super 来调用两个接口中的 eat 方法。上代码：12345678910111213141516171819202122class Cat implements Action1, Action2 &#123; @Override public void eat() &#123; Action1.super.eat(); &#125; /*@Override public void eat() &#123; Action2.super.eat(); &#125;*/ /*@Override public void eat() &#123; Action1.super.eat(); Action2.super.eat(); Action1.fun(); &#125;*/ @Override public void call() &#123; &#125;&#125; 方法引用方法引用通过方法的名字来指向一个方法，方法引用可以使语言的构造更紧凑简洁，减少冗余代码，方法引用使用一对冒号 :: 表示。当要传递给Lambda体内的操作已经有实现的方法了，就可以使用方法引用了。 先定义一个函数式接口和一个测试类以及类中的一些方法：123interface Say&lt;T&gt; &#123; void accept(T t1, T t2);&#125; 12345678910111213141516171819202122232425262728293031323334public class Student &#123; private String name = &quot;default&quot;; public Student() &#123; &#125; public Student(String name) &#123; this.name = name; &#125; public static Student create(Supplier&lt;Student&gt; studentSupplier) &#123; return studentSupplier.get(); &#125; public static String study() &#123; System.out.println(&quot;study&quot;); return &quot;knowledge&quot;; &#125; public String fun() &#123; System.out.println( &quot;fun&quot;); return &quot;fun&quot;; &#125; public void ask() &#123; System.out.println(this.getName() + &quot; ask&quot;); &#125; public void say(Student student) &#123; System.out.println(this.getName() + &quot; say to&quot; + student.getName()); &#125; //set get 方法已省略&#125; 通过 main 方法测试方法引用的具体使用方式：123456789101112131415161718192021222324public static void main(String[] args) &#123; //构造器引用：它的语法是Class::new，或者更一般的Class&lt; T &gt;::new Student student = Student.create(Student :: new ); Student student1 = Student.create(() -&gt; new Student(&quot;小红&quot;)); Student student2 = Student.create(() -&gt; new Student(&quot;小绿&quot;)); //静态方法引用：它的语法是Class::static_method Supplier&lt;String&gt; supplier1 = Student :: study; System.out.println(supplier1.get()); //特定类的任意对象的方法引用：它的语法是Class::method Consumer&lt;Student&gt; consumer = Student :: ask; //下面 student 参数是 ask 方法的调用者 consumer.accept(student); //特定类的任意对象的方法引用：它的语法是Class::method Say&lt;Student&gt; say = Student :: say; //下面 student1 参数是 say 方法的调用者，student2 参数是 say 方法的参数 say.accept(student1, student2); //特定对象的方法引用：它的语法是instance::method supplier1 = student :: fun; System.out.println(supplier1.get());&#125; 注意上面静态方法引用和特定类的任意对象的方法引用的区别，前者是一个静态方法，可通过类访问，后者则是参数列表的第一个参数是实例方法的调用者，第二个参数(或无参)是实例方法的参数时才会采取这种语法。 在使用方法引用时一定注意： 方法引用所引用的方法的参数列表必须要和函数式接口中抽象方法的参数列表完全一致。 方法引用所引用的方法的的返回值必须要和函数式接口中抽象方法的返回值完全一致]]></content>
      <categories>
        <category>Java 8</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统下 AES 解密报错问题]]></title>
    <url>%2FLinux-%E7%B3%BB%E7%BB%9F%E4%B8%8B-AES-%E8%A7%A3%E5%AF%86%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前两天在开发中遇到一个问题，就是一个服务部署在 Window 系统上的，而另一个服务部署在 Linux 系统上，Linux 系统上的服务需要通过 WebService 向 Window 系统上的服务获取数据，而这个数据是经过 AES 加密的，获取到密文之后需要进行解密，然后拿到解密之后的数据进行处理，但是在 Linux 系统服务上进行解密时却报错了，下面就是报错信息。 遇到错误第一时间找度娘 ( 其实应该找 Google )，结果发现原来是操作系统的原因，Linux 系统下在进行 AES 加解密时生成 key 时是有问题的，key 值的生成方式如下：1234KeyGenerator generator = KeyGenerator.getInstance(&quot;AES&quot;);//password 为加解密使用的密钥generator.init(128, new SecureRandom(password.getBytes()));Key key = generator.generateKey(); SecureRandom 的实现尝试完全随机化生成器本身的内部状态，因此随操作系统本身的內部状态而定，该实现在 windows 上每次生成的 key 都相同，但是在 linux 系统上则不同，除非调用方在调用 getInstance 方法之后又调用了 setSeed 方法，将上述生成 key 值的方式改为如下：1234567KeyGenerator generator = KeyGenerator.getInstance(&quot;AES&quot;);//generator.init(128, new SecureRandom(password.getBytes()));SecureRandom secureRandom = SecureRandom.getInstance(&quot;SHA1PRNG&quot;);//password 为加解密使用的密钥secureRandom.setSeed(password.getBytes());generator.init(128, secureRandom);Key key = generator.generateKey(); 上面只是修改了 key 值的生成方式，这样就能够避免在 Linux 系统上加解密失败的错误了。完整的 AES 加解密工具类如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package com.ecjtu.common.util;import sun.misc.BASE64Decoder;import sun.misc.BASE64Encoder;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import java.security.Key;import java.security.NoSuchAlgorithmException;import java.security.SecureRandom;/** * @author zhouxh */public class AesEncodeUtil &#123; public static void main(String[] args) &#123; String content = &quot;www.baidu.com&quot;; String pwd = &quot;ecjtu&quot;; System.out.println(&quot;加密前content：&quot; + content); // 加密 String enContent = encodeByAes(content, pwd); System.out.println(&quot;加密后content：&quot; + enContent); // 解密 String deContent = decodeByAes(enContent, pwd); System.out.println(&quot;解密后content：&quot; + deContent); &#125; /** * 加密 * * @param content 待加密内容 * @param password 加密密钥 * @return */ public static String encodeByAes(String content, String password) &#123; Key key = generateKey(password); BASE64Encoder base64en = new BASE64Encoder(); try &#123; // 创建密码器 Cipher cipher = Cipher.getInstance(&quot;AES&quot;); byte[] byteContent = content.getBytes(&quot;utf-8&quot;); // 初始化 cipher.init(Cipher.ENCRYPT_MODE, key); // 加密 content = base64en.encode(cipher.doFinal(byteContent)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return content; &#125; /** * 解密 * * @param content 待解密内容 * @param password 解密密钥 * @return */ public static String decodeByAes(String content, String password) &#123; Key key = generateKey(password); BASE64Decoder base64de = new BASE64Decoder(); try &#123; byte[] byteContent = base64de.decodeBuffer(content); // 创建密码器 Cipher cipher = Cipher.getInstance(&quot;AES&quot;); // 初始化 cipher.init(Cipher.DECRYPT_MODE, key); // 解密 content = new String(cipher.doFinal(byteContent), &quot;UTF8&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return content; &#125; /** * 根据密钥生成加解密使用的 key 值 * * @param password 加解密密钥 * @return */ public static Key generateKey(String password) &#123; Key key = null; try &#123; KeyGenerator generator = KeyGenerator.getInstance(&quot;AES&quot;); //下面这种方式在 Linux 系统下会报错 //generator.init(128, new SecureRandom(password.getBytes())); SecureRandom secureRandom = SecureRandom.getInstance(&quot;SHA1PRNG&quot;); secureRandom.setSeed(password.getBytes()); generator.init(128, secureRandom); key = generator.generateKey(); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; return key; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Effective Java - 创建和销毁对象]]></title>
    <url>%2FEffective-Java-%E5%88%9B%E5%BB%BA%E5%92%8C%E9%94%80%E6%AF%81%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[遇到多个构造器参数时要考虑用构建器当我们的类的一些属性是必须的，有些属性是可选的，参数较多的情况下我们可以适当考虑使用构建器，其实在 Java 开发中我们也经常遇到这种通过构建器来创建类实例的情况，然后再结合链式调用写出来的代码还是比较美观的。下面结合一个简单的例子来说明：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package com.ecjtu;import java.util.Arrays;/** * @author zhouxh */public class User &#123; private String username; private String password; private String phone; /** * 可选参数 */ private Integer sex; /** * 可选参数 */ private String birthday; /** * 可选参数 */ private String[] hobby; public static class Builder &#123; private String username; private String password; private String phone; /** * 可选参数,给个默认值 */ private Integer sex = 1; /** * 可选参数,给个默认值 */ private String birthday = &quot;0-0-0-0&quot;; /** * 可选参数,给个默认值 */ private String[] hobby = new String[]&#123;&#125;; public Builder(String username, String password, String phone) &#123; this.username = username; this.password = password; this.phone = phone; &#125; public Builder sex(Integer sex) &#123; sex = sex; return this; &#125; public Builder birthday(String birthday) &#123; birthday = birthday; return this; &#125; public Builder hobby(String[] hobby) &#123; hobby = hobby; return this; &#125; public User build() &#123; return new User(this); &#125; &#125; private User(Builder builder) &#123; username = builder.username; password = builder.password; phone = builder.phone; sex = builder.sex; birthday = builder.birthday; hobby = builder.hobby; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;username=&apos;&quot; + username + &apos;\&apos;&apos; + &quot;, password=&apos;&quot; + password + &apos;\&apos;&apos; + &quot;, phone=&apos;&quot; + phone + &apos;\&apos;&apos; + &quot;, sex=&quot; + sex + &quot;, birthday=&apos;&quot; + birthday + &apos;\&apos;&apos; + &quot;, hobby=&quot; + Arrays.toString(hobby) + &apos;&#125;&apos;; &#125;&#125; User 对象的创建：123456public class App &#123; public static void main(String[] args) &#123; User user = new User.Builder(&quot;admin&quot;, &quot;123456&quot;, &quot;13999999999&quot;).sex(0).build(); System.out.println(user.toString()); &#125;&#125; 当然，这里只是一个简单的小例子，开发中一般不会用这种方式来创建实体类，可能还是需要看个人开发时具体情况决定是否采用这种方式，这里只对这种创建方式做一个简单的介绍。 避免创建不必要的对象一般来说，最好能重用对象而不是在每次需要时都去频繁的创建，重用的方式快，而且能够避免频繁创建浪费资源。像下面这种情况就推荐重用对象,可以对比以下两种方式的差别。123456789101112131415161718192021222324package com.ecjtu;import java.util.Calendar;import java.util.Date;import java.util.TimeZone;/** * 不推荐这样做 * * @author zhouxh */public class Person1 &#123; private final Date birthDate = new Date(); public boolean isBabyBoomer() &#123; Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(&quot;GMT&quot;)); calendar.set(1946, Calendar.JANUARY, 1, 0, 0, 0); Date boomStart = calendar.getTime(); calendar.set(1965, Calendar.JANUARY, 1, 0, 0, 0); Date boomEnd = calendar.getTime(); return birthDate.compareTo(boomStart) &gt;= 0 &amp;&amp; birthDate.compareTo(boomEnd) &lt; 0; &#125;&#125; 12345678910111213141516171819202122232425262728293031package com.ecjtu;import java.util.Calendar;import java.util.Date;import java.util.TimeZone;/** * 推荐这样做 * * @author zhouxh */public class Person2 &#123; private final Date birthDate = new Date(); private static final Date BOOM_START; private static final Date BOOM_END; static &#123; Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(&quot;GMT&quot;)); calendar.set(1946, Calendar.JANUARY, 1, 0, 0, 0); BOOM_START = calendar.getTime(); calendar.set(1965, Calendar.JANUARY, 1, 0, 0, 0); BOOM_END = calendar.getTime(); &#125; public boolean isBabyBoomer() &#123; return birthDate.compareTo(BOOM_START) &gt;= 0 &amp;&amp; birthDate.compareTo(BOOM_END) &lt; 0; &#125;&#125; 消除过期的对象引用我们在日常开发中可能稍有不慎就会遇到内存泄漏的问题，这需要我们从细节去防止这种情况的发生，一般而言，只要类是自己管理内存，就应该警惕内存泄漏的问题。下面展示一种可能会发生内存泄漏的情况：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.ecjtu;import java.util.Arrays;import java.util.EmptyStackException;/** * @author zhouxh */public class Stack &#123; private Object[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() &#123; elements = new Object[DEFAULT_INITIAL_CAPACITY]; &#125; public void push(Object object) &#123; ensureCapacity(); elements[size++] = object; &#125; public Object pop1() &#123; if (size == 0) &#123; throw new EmptyStackException(); &#125; return elements[--size]; &#125; public Object pop2() &#123; if (size == 0) &#123; throw new EmptyStackException(); &#125; Object result = elements[--size]; /* 将弹出的值赋空，以便 jvm 回收，如果不赋空将不会被 jvm 回收，因为栈内部依然维护着这些对象的过期引用。 过期引用是指永远不会被解除的引用，在这里就是指在 elements 数组活动之外的引用，即元素下标小于 size 的那些元素。 所以一旦数组元素变成了非活动部分的一部分就应该手动清空这些数组元素。 */ elements[size] = null; return result; &#125; private void ensureCapacity() &#123; if (elements.length == size) &#123; elements = Arrays.copyOf(elements, 2 * size + 1); &#125; &#125;&#125; 这个随着栈的不断的弹栈和压栈，每次弹出如果不清空该引用，随着量的增加就可能造成内存泄漏的情况。]]></content>
      <categories>
        <category>Effective Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统下远程连接和远程拷贝命令]]></title>
    <url>%2FLinux-%E7%B3%BB%E7%BB%9F%E4%B8%8B%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E5%92%8C%E8%BF%9C%E7%A8%8B%E6%8B%B7%E8%B4%9D%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[在平常开发部署中，我们可能经常需要远程连接到服务器上执行一些操作，有时还需要拷贝相应的文件过去，这里记录下平常自己用的比较多的远程连接命令以及远程拷贝文件的命令。 远程连接 ssh 命令1ssh zhouxh@192.168.0.134 上面是通过默认 22 端口连接，如果需要指定端口连接，加上 -p 参数指定相应端口：1ssh -p 33109 zhouxh@192.168.0.134 远程拷贝 scp 命令将本地文件 file1 拷贝到另一台主机用户名为 zhouxh 的家目录下：1scp /home/zhouxh/file1 zhouxh@192.168.0.134:/home/zhouxh/ 将本地目录 dir1 拷贝到另一台主机用户名为 zhouxh 的家目录下： 1scp -r /home/zhouxh/dir1 zhouxh@192.168.0.134:/home/zhouxh/ 将另一台主机用户名为 zhouxh 的家目录下的文件 file1 拷贝到本地家目录下： 1scp zhouxh@192.168.0.134:/home/zhouxh/file1 /home/zhouxh/ 将另一台主机用户名为 zhouxh 的家目录下的 dir1 目录拷贝到本地家目录下： 1scp -r zhouxh@192.168.0.134:/home/zhouxh/dir1 /home/ 以上拷贝命令都是通过默认 22 端口拷贝，如果需要指定端口，加上 -P 参数，注意 P 大写： 1scp -P 33109 /home/zhouxh/file1 zhouxh@192.168.0.134:/home/zhouxh/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 系统安装以及一些开发中必要的安装配置]]></title>
    <url>%2FUbuntu-%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%BC%80%E5%8F%91%E4%B8%AD%E5%BF%85%E8%A6%81%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[对于开发人员来说，个人强烈推荐使用 Linux 系统进行开发，至于为什么，这里贴出自己刚开始尝试使用 Linux 系统时看的一个博主写的文章，可以说就是因为看了这位博主的文章才立即决定装上 Linux 系统，开始了我的 Linux 系统之旅，从此停不下来了。下面就是这位博主写的文章地址，里面详细阐述了为什么要使用 Linux 系统。http://ghosertblog.github.io/blog/2012/10/14/ubuntu-living-handbook/Ubuntu桌面生存指南 (1) — 选择 Linux 这位博主写了 5 篇文章关于 Linux 系统的，建议从第一篇开始看，一直看下去，看完之后如果还是不想进入 Linux 系统的世界，那么可能 Linux 系统与你无缘，这里并无冒犯的意思，纯属个人喜好。 博主从零开始全面的介绍了 Linux 系统，（当然还是要有点 Linux 系统的基础去看更好）一直到 Linux 系统的安装以及后面的维护和备份，值得去好好的看一遍，那么这里我主要是想记录下自己的安装过程以及开发中的一些必要软件安装和配置，以防以后重复去搜索资源。 Ubuntu 系统的安装U 盘启动盘制作对于 Linux 系统的启动盘制作很简单，只需要下载一个制作工具即可，下载链接如下： U 盘启动盘制作软件 下载完制作工具后，准备好 Linux 系统镜像文件，以 Ubuntu 镜像为例，最好去官网下载最新的，而且带有 LTS 结尾的 ISO 文件，下载好以后打开刚才下载的制作软件 图中三处标红的地方从上到下分别是制作的启动盘要安装的镜像类型，准备好的镜像文件位置，要制作的 U 盘。这里提醒记得备份 U 盘里面的重要资料，制作完成之后会全部格式化。选择好之后点击 create 按钮，等个十来分钟应该就会出现如下字样了。 到这里 U 盘启动盘就已经制作好了，接下来就是插入你要安装系统的笔记本或者台式机上，设置好从 U 盘启动，进入系统后出现以下界面(有的版本不一样可能不会立马进入这个界面，会直接进入安装界面，可以点击旁边的 Try Ubuntu 按钮来进入这个界面，直接安装可能会出问题) 在从这里点击进入安装界面，接下来就是按照指示进行操作即可，实在不懂的可以百度找一下具体的安装步骤，中间分区的步骤尽量自己来进行分区，具体的分区方案以下供参考： 一般来说一个 Ubuntu 的系统在安装之初应该有三个分区，他们分别是挂载于根目录： /, home 目录： /home 的两个分区以及 swap 分区。swap 分区是指虚拟内存的交换区，一般设置为实际内存容量的两倍大小即可。假如有一台 8G 内存，1T 磁盘的笔记本电脑，swap: 15G 15360M，/: 100G 102400M/boot: 20G 20480M，/home: 剩余空间都分给 home 安装 Ubuntu Linux 系统时硬盘分区最合理的方法win7 下制作 Ubuntu 系统安装启动盘和 U 盘安装 Ubuntu 全过程 Ubuntu 系统软件源配置到这里 Ubuntu 系统应该安装完成了，接下来就可以配置日常开发中需要的工具软件了软件源配置：Ctrl + Alt + T 快捷键打开终端命令行，输入 update-manager 回车打开软件更新器，这时可能会提示检查更新，可以选择稍后提醒， Ubuntu 系统软件后台启动在 Ubuntu 系统的终端运行软件会将终端占据，这样你不得不重新启动一个终端来执行命令，这里有一个脚本配置软件从后台启动，不会占据终端。在 home 目录下创建 bin目录，然后在 bin 目录下新建一个文本文件，命名 x ，文件内容如下： 12#!/bin/sh&quot;$@&quot; 1&gt;/dev/null 2&gt;&amp;1 &amp; 并且给这个脚本文件添加可执行权限，这个脚本的大意是运行软件的时候，不输出任何标准信息和错误信息，并且在后台运行，这样就可以避免占据终端的行为。比如启动火狐浏览器： 1x Firefox Ubuntu 系统 vi 编辑器配置在终端中输入： 1$ set -o vi 可以开启以兼容 vi 的快捷键操作 bash 命令，此时你可以在终端使用 Esc 切换到命令模式，在命令模式下，按 h，l 可以左右移动光标，按 j，k 可以切换前一条后一条命令。x可以修改字符，”$， ^”可以返回命令尾部或头部，i 可以返回编辑模式。Vi/Vim 本身不需要安装，但是如果你更乐衷于视觉效果更好，功能更丰富的 GUI 版本可以安装GVim: 1$ sudo apt-get install vim-gnome 执行以下命令进入 vi 编辑器训练教程：1vimtutor Ubuntu 系统终端分屏工具 Tmux 运行安装： 1$ sudo apt-get install tmux 安装过程中如果遇到由于包依赖问题导致安装失败的话，可以尝试下面命令进行修复 1sudo apt-get -f install 个性化配置： 12345cd ~rm -rf .tmuxgit clone https://github.com/gpakosz/.tmux.gitln -s .tmux/.tmux.confcp .tmux/.tmux.conf.local . 相关链接：tmux 的使用Tmux 速成教程：技巧和调整tmux的使用方法和个性化配置 Ubuntu 系统安装 Chrome 浏览器在终端中，执行以下四条命令： 1234sudo wget http://www.linuxidc.com/files/repo/google-chrome.list -P /etc/apt/sources.list.d/wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -sudo apt-get updatesudo apt-get install google-chrome-stable Ubuntu 系统安装 JDK去官网下载 Ubuntu 系统的 JDK 开发工具压缩包，解压到某个文件夹中，然后配置环境变量，以下是我电脑上的一些环境变量配置，我这里是配置在 /etc/profile 文件中的，对所有用户有效： 1sudo vi /etc/profile 123456export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_144export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport ZOO_HOME=/home/zhouxh/software/zookeeper-3.4.11export M2_HOME=/opt/maven/apache-maven-3.5.0export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;M2_HOME&#125;/bin:$&#123;ZOO_HOME&#125;/bin:/usr/local/curl/bin:$PATH 配置好后要想环境变量立即生效可以执行以下命令,或者重启生效 1source /etc/profile Ubuntu 系统安装截图工具 deepin-scrot 并且配置快捷键执行以下命令下载截图工具： 1wget http://packages.linuxdeepin.com/deepin/pool/main/d/deepin-scrot/deepin-scrot_2.0-0deepin_all.deb 截图工具安装： 12sudo apt-get install python-xlibsudo dpkg -i deepin-scrot_2.0-0deepin_all.deb 当安装失败时可能是由于依赖问题，执行下面命令进行修复之后继续安装： 12sudo apt-get -f installsudo dpkg -i deepin-scrot_2.0-0deepin_all.deb deepin-scrot 截图快捷键设置： xkill 快捷键配置， 关闭无响应的程序： 返回桌面快键键配置，换回 window 系统下熟悉的 super + d 快捷键： 可能有时返回桌面的快捷键配置后还是没用，super + d 无法返回到桌面，这时需要做以下设置：首先安装 compizconfig-settings-manager： 1sudo apt-get install compizconfig-settings-manager 然后在终端输入 compizconfig-settings-manager 命令打开该软件，找到 Ubuntu Unity plugin，General 里面有个 Show Desktop，设置一下相应快捷键就可以了。 Ubuntu 系统微信、QQ、Listen 安装微信安装参考 GitHub 上面的一个项目，里面有已经发布好了的，直接下载解压后即可使用，链接如下： GitHub 微信项目链接 QQ 安装参考下面博主写的教程： Ubuntu 18.04安装最新版QQ（9.0）在ubuntu17.04下安装最新版QQ教程 Listen 是一款听音乐的 App，集成了网易，虾米，QQ 音乐，你想听的里面基本上能够搜到，而且界面也很符合我们开发者的风格，可以说很良心了，网站链接： Listen 网站链接打开该网站下载 Linux 版本即可，他还有浏览器插件版，不想安装的话也可以直接下载浏览器插件版。 最后如果必须要用到 Windows 系统下面的软件的话，那就只能推荐一款软件给你了：Virtual Box 安装： 123sudo apt-get install virtualboxsudo apt-get install virtualbox-guest-additionssudo apt-get install virtualbox-guest-additions-iso 使 Virtualbox 辨认出物理 USB 外设 1sudo apt-get install gnome-system-tools]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统下的软链接和硬链接]]></title>
    <url>%2FLinux-%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E8%BD%AF%E9%93%BE%E6%8E%A5%E5%92%8C%E7%A1%AC%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[之前一直不是很明白 Linux 系统下的软链接 (soft link) 和硬链接 (hard link) 的区别和用法，今天刚好又用到了，特意花了点时间去了解了一下，暂且在这里记录一下吧。 在介绍硬链接和软链接之前先介绍一下 Linux 系统下面的文件结构，文件在 Linux 下可以分为两个部分：元数据和用户数据。元数据中主要包含文件的一些附加属性，比如：文件大小，创建时间，所有者信息以及 文件的 inode 索引号，inode 索引号是文件索引节点号，也是文件的唯一标识，我们平常看到的文件名并非是用来区分文件而是一个别名便于我们识别和记忆；用户数据则是文件的数据块内容，也就是该文件保存的真正内容。 硬链接(1) 含义硬链接表示的是一个文件的 inode 索引号对应于多个文件名，也就是说我们对一个文件创建了多个文件名，它们都对应于同一个 inode 索引号标识的文件，当我们删除其中任意一个文件名，都不会对其他文件名有影响，每删一个文件名，该文件的链接数减一，只有当该文件的链接数为 0 时系统会将其数据块和 inode 索引号回收。 (2) 创建方式eg. 为 /root/fileA 创建硬链接 /home/fileB 1ln /root/fileA /home/fileB 注意：应该使用文件的绝对路径，避免使用相对路径。 (3) 特性 文件有相同的 inode 及 data block 删除一个硬链接文件并不影响其他有相同 inode 号的文件 文件的链接数为 0 时系统会将其数据块和 inode 索引号回收 (4) 使用限制 不能对目录创建硬链接，只能对文件创建 不能对不同的文件系统创建硬链接,即两个文件名要在相同的文件系统下 只能对已存在的文件进行创建 软链接(1) 含义软链接其实就是一个普通的文件，有着自己的 inode 索引号和数据块，特殊的是该文件的用户数据块中存放的是另一个文件的路径，有点类似于 Windows 系统中的快捷方式，通过快捷方式可以打开它所指向的文件，链接文件的删除不影响该链接文件数据块存放的路径指向的文件。 (2) 创建方式eg. 为 /root/fileA 创建软链接 /home/fileB 1ln -s /root/fileA /home/fileB 注意：应该使用文件的绝对路径，避免使用相对路径。 (3) 特性 软链接有自己的文件属性及权限等 创建软链接时，链接计数不会增加 删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接） (4) 使用限制 可以跨文件系统创建 可以对文件或者目录创建 可以对一个不存在的文件或者目录创建 文件类型最后说一下文件的类型主要有以下几种： 1234567d ：目录 - ：文件 l ：链接 s ：socket p ：named pipe b ：block device c ：character device]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 下 MySQL 安装以及配置远程可访问]]></title>
    <url>%2FUbuntu-%E4%B8%8B-MySQL-%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE%E5%8F%AF%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[Ubuntu 安装 MySQL最好先执行一次更新操作： 1sudo apt-get update 然后执行以下三条命令： 123sudo apt-get install mysql-serversudo apt-get isntall mysql-clientsudo apt-get install libmysqlclient-dev 安装成功后可以通过下面的命令测试是否安装成功： 1sudo netstat -tap | grep mysql 出现如下信息证明 MySQL 安装成功：​ 对于 Ubuntu 系统下安装 MySQL 后一般都不支持远程连接，只能通过 localhost 或者 127.0.0.1 进行连接，因此需要我们自己去配置，这里介绍两种方式： 创建一个新的访问用户，配置该用户可以远程访问。(推荐使用这种方式)(1) 在安装好了 MySQL 数据库之后，由于 MySQL 数据库安装好之后出于安全考虑默认就是只允许通过本机访问，即只能通过 127.0.0.1 或者 localhost 去访问，所以首先需要修改 MySQL 的配置文件，在 Ubuntu 系统下, MySQL 的配置文件在路径 /etc/mysql/mysql.conf.d/ 下,找到该路径下的 mysqld.cnf 文件打开找到如下位置:​ 红色标注部分这里就是 MySQL 默认只能由本机访问，我们将其注释掉。注释之后最好将服务重启，之后再进行创建用户以及赋予相应权限的操作。 (2) 在本机使用 root 用户登录到 MySQL 数据库： 1mysql -u root -p 回车后输入密码登录。(3) 创建用户： 1create user username identified by &apos;password&apos;; username 是你要创建的用户名，password 为密码。 (4) 给创建的用户添加权限： 1grant all privileges on *.* to &apos;username&apos;@&apos;%&apos; identified by &apos;password&apos; with grant option; 上面的 all 代表接受所有操作，比如 select,insert,delete….; . 代表所有数据库下面的所有表，也就是所有权限;而 % 代表这个用户允许从任何地方登录；为了安全期间，这个 % 可以替换为你允许的 ip 地址。username 表示你要赋予权限的用户名，password 表示该用户名对应的密码。 (5) 修改后刷新权限： 1flush privileges; (6) 执行完上面的操作后，输入 quit 命令退出数据库将 MySQL 服务重启： 1sudo service mysql restart (7) 重启之后用刚才创建好的用户并且使用本机的 IP 地址进行测试，输入如下命令登录: 1mysql -h 192.168.0.161 -u username -p 192.168.0.161 表示 MySQL 服务所在机器的 IP 地址，username 为刚才新创建的用户名，回车后输入密码，再回车登录成功表示配置已经生效了。否则需要再检查一遍其他哪里没有配置好。 修改当前 root 用户的配置，使该用户可以远程访问同样的先执行第一种方式中步骤一和步骤二，然后执行以下语句： 1grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;password&apos; with grant option; 1flush privileges; 之后将 MySQL 服务重启，重启之后用 root 用户通过 IP 地址登录测试。 1mysql -h 192.168.0.161 -u root -p 两种方式本质是一样的，只不过第二种更省事，直接在已有的 root 用户上进行更改，但这样不是很安全，所以推荐第一种方式，配置权限时可以指定一些权限，也可以指定 IP 地址可远程访问。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 执行命令时报错 unable to resolve host]]></title>
    <url>%2FUbuntu-%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E6%97%B6%E6%8A%A5%E9%94%99-unable-to-resolve-host%2F</url>
    <content type="text"><![CDATA[记录一下今天遇到的一个问题今天在阿里云服务器上部署应用时遇到一个小问题，每次执行完 sudo 命令都会出现一行错误信息，刚开始还以为执行命令出错了，但仔细一看不像是执行命令的报错信息，而且还发现命令其实已经执行成功了。 执行命令之后的报错信息如下： 于是去百度了一波，发现原来是因为 /etc/ 路径下 hosts 文件中的主机名和 hostname 文件中的主机名不一致所导致的错误。 经查看 hostname 文件中的主机名如下： 知道原因了之后就知道如何解决了，方式如下: 在 /etc/ 路径下 hosts 文件中添加一行，将 /etc/ 路径下 hostname 文件中的主机名称拷贝过来即可，hosts 文件修改之后如下： 以下则分别是我电脑上 /etc 路径下 hosts 文件和 hostname 文件中的内容 比如上面我电脑上 hostname 文件中内容是 zhouoxh-X550VC ，只要在 hosts 文件中添加一行 127.0.1.1 zhouxh-X550VC，如果不加这一行执行 sudo 命令就会报错。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java 面试系列——基础篇(二)]]></title>
    <url>%2FJava-%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%AF%87-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[Java 中 equals 与 == 的区别通俗的来说，“==” 比较的是地址，equals 比较的是内容。也就是说前者比较的是对象(堆)在(栈)内存中存放的内存地址，用来判断两个对象的地址是否相同，即是否是指向同一个对象。后者用来比较的是两个对象的内容是否相等，由于所有的类都是继承自java.lang.Object 类的，所以适用于所有对象，注意如果没有对该方法进行重写的话，调用的仍然是 Object 类中的方法，而 Object 中的 equals 方法返回的却是内存地址比较的结果，方法内容如下 ： 123public boolean equals(Object obj) &#123; return (this == obj);&#125; hashCode 和 equals 方法的区别与联系hashCode 和 equals 方法都是 Object 中的方法，其中 hashCode 方法是 Native 修饰，该方法是计算出对象实例的哈希码，又称哈希函数，计算方式依赖于对象实例的内存地址，所以一般来说，每个对象实例的哈希码都是唯一的，当然如果对该方法进行重写了，结果也就不一样了。而 equals 方法一般是用来比较两个对象实例的值是否相等，当然如果没有对该方法进行重写，比较的就是两个对象的地址是否相等。 他们之间的联系就是当两个对象的 equals 相等那么 hashCode 一定相等，hashCode 不等那么equals 一定不等。反之 hashCode 相等，equals 不一定相等，因为哈希散列值有冲突的时候，当然好的哈希算法冲突的几率比较小。 其次在我们开发当中，一般都会同时对这两个方法进行重写，如果只重写其中一个或者都不重写当我们将这个对象放入 Map 集合或者 Set 集合中时就会出问题了。如果只重写了 hashCode 方法没有重写 equals 方法，那么就会出现 hashCode 值相同时，这时找到数组同一个位置的元素链表，由于没有重写 equals 方法导致向 Map 中取元素时找不到你要找的元素；当向 Map 集合中放入元素时就会放入重复的元素，因为此时比较的是两个元素的内存地址。如果只重写了 equals 方法没有重写 hashCode 方法，当你向 Map 中获取元素时，第一步比较 hashCode 值时就已经不等，所以也就找不到你想要找的元素了；当你向 Map 中放入元素时，第一步比较就始终定位在数组的不同的位置，这样也就达不到覆盖 key 值相同的元素，Set 集合也达不到去重的效果了。 还有就是对于需要大量并且快速的对比的话如果都用 equals 方法做比较显然效率太低，所以解决方式是每当需要对比的时候，首先用 hashCode 方法进行对比，如果hashCode 不一样，则表示这两个对象肯定不相等（也就是不必再用 equals 对比了），如果 hashCode 相同，此时再通过 equals 方法对比，如果 equals 也相同则表示这两个对象是真的相同了，这样既能大大提高效率也保证对比的绝对正确性！ 总之，这两个方法对实现 HashMap 的精确性和正确性，以及对 Set 集合中去重功能的实现至关重要，以下 String 类中的 hashCode 方法和 equals 方法： 123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } 什么是 Java 序列化和反序列化，如何实现 Java 序列化？或者请解释 Serializable 接口的作用序列化就是一种用来处理对象流的机制,所谓对象流也就是将对象的内容进行流化。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间，序列化是为了解决在对对象流进行读写操作时所引发的问题。反序列话则刚好相反，将流化后的对象重新恢复成对象状态就称为反序列化。序列化的实现:将需要被序列化的类实现 Serializable 接口,该接口没有需要实现的方法，实现 Serializable 接口只是为了标注该对象是可被序列化的，然后使用一个输出流(如:FileOutputStream)来构造一个 ObjectOutputStream (对象流)对象，接着使用ObjectOutputStream 对象的 writeObject(Object obj) 方法就可以将参数为 obj 的对象写出(即保存其状态)，要恢复的话则使用输入流。 Object 类中常见的方法，为什么 wait notify 会放在 Object 里边？123456789101112public String toString() &#123;&#125;public boolean equals(Object obj) &#123;&#125;public native int hashCode();protected void finalize() throws Throwable &#123;&#125;public final native Class&lt;?&gt; getClass();protected native Object clone() throws CloneNotSupportedException;public final void wait() throws InterruptedException &#123;&#125;public final native void wait(long timeout) throws InterruptedException;public final void wait(long timeout, int nanos) throws InterruptedException &#123;&#125;public final native void notify();public final native void notifyAll();private static native void registerNatives(); 以上便是 Object 类中所有的方法，其中 toString(), equals(), hashCode() 三个方法是我们见的相对较多的，finalize() 这个方法是由垃圾收集器在确定这个对象没有被引用时在释放对象占用的内存之前会调用该方法，clone() 方法是给对象创建一个自己的副本，前提是对象已经实现了 Cloneable 接口，否则抛出 CloneNotSupportedException，getClass() 方法返回此对象的运行时类型。 wait 有三个重载方法，同时必须捕获非运行时异常 InterruptedException。 wait() 进入等待，需要 notify()，notifyAll() 才能唤醒 wait(long timeout) 进入等待，经过 timeout 超时后，若未被唤醒，则自动唤醒 wait(timeout, nanos) 进入等待，经过 timeout 超时后，若未被唤醒，则自动唤醒。相对 wait(long timeout) 时间更加精确。 wait() 和 notify() 以及 notifyAll() 则是用来控制线程的状态的，它们必须在 synchronized 同步关键字所限定的作用域中调用，否则会报错 java.lang.IllegalMonitorStateException，意思是因为没有同步，所以线程对象锁的状态是不确定的，不能调用这些方法。同时 synchronized 关键字锁可以是任意对象，任意对象调用的方法则一定是定义在 Object 类中。 wait 表示持有对象锁的线程准备释放对象锁，释放资源并进入等待状态，直到它被其他线程通过 notify() 或者 notifyAll() 唤醒。 notify 表示持有对象锁的线程准备释放对象锁，调用 notify() 通知 JVM 随机选择一个在该对象上调用 wait() 方法的线程，解除其阻塞状态使其获得对象锁，synchronized 代码作用域结束后，随机选择的那个线程获得对象锁，其他调用 wait() 方法的线程继续等待，直到有新的 notify() 或者 notifyAll() 被调用。 notifyAll 表示持有对象锁的线程准备释放对象锁，调用 notifyAll() 通知 JVM 唤醒所有在该对象上调用 wait() 方法的线程的阻塞状态, synchronized 代码作用域结束后，JVM 通过算法将对象锁指派给其中一个线程，当前获得对象锁的线程 synchronized 代码作用域结束后，然后所有被唤醒的线程不再等待，之前所有被唤醒的线程都有可能获得该对象锁权限，这个由 JVM 算法决定。]]></content>
      <categories>
        <category>面试系列</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java 面试系列——基础篇(一)]]></title>
    <url>%2FJava-%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%AF%87-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[面向对象的特征：封装、继承、多态、抽象封装给对象提供了隐藏内部特性和行为的能力，对象提供一些能被其他对象访问的方法来改变它内部的数据。在 Java 当中，有 4 种访问权限，对应有三个修饰符 : public、private 、protected，每一种修饰符给其他的位于同一个包或者不同包下面对象赋予了不同的访问权限。下面列出了使用封装的一些好处: 通过隐藏对象的属性来保护对象内部的状态 提高了代码的可用性和可维护性,因为对象的行为可以被单独的改变或者是扩展 禁止对象之间的不良交互提高模块化 继承给对象提供了从基类获取字段和方法的能力、继承提供了代码的重用行、在不修改类的情况下给现存的类添加新特性。 多态是编程语言给不同的底层数据类型做相同的接口展示的一种能力，一个多态类型上的操作可以应用到其他类型的值上面。 抽象是把想法从具体的实例中分离出来的步骤,因此,要根据他们的功能而不是实现细节来创建类，Java 支持创建只暴漏接口而不包含方法实现的抽象的类，这种抽象技术的主要目的是把类的行为和实现细节分离开。 备注: 抽象和封装是互补的概念。一方面,抽象关注对象的行为。另一方面,封装关注对象行为的 细节。一般是通过隐藏对象内部状态信息做到封装,因此,封装可以看成是用来提供抽象的一种策略。 final, finally, finalize 的区别final : 修饰符(关键字)，如果一个类被声明为 final，意味着它不能再派生出新的子类，不能作为父类被继承。因此一个类不能既被声明为 abstract 的,又被声明为 final 的。将变量或方法声明为 final,可以保证它们在使用中不被改变。被声明为 final 的变量必须在声明时给定初值,而在以后的引用中只能读取,不可修改。被声明为 final 的方法也同样只能使用,不能重载。 finally : 在异常处理时提供 finally 块来执行资源释放操作，如果抛出一个异常，那么相匹配的 catch 子句就会执行,然后就会进入 finally 块(如果有的话)。 finalize : 方法名，Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作，这个方法是由垃圾收集器在确定这个对象没有被引用时在释放对象占用的内存之前会调用该方法，它是在 Object 类中定义的，因此所有的类都继承了它，子类覆盖 finalize() 方法以整理系统资源或者执行其他清理工作。 Exception、Error、运行时异常与一般异常有何异同error 表示程序运行出错了，它是一种比较严重的问题，比如说内存溢出，不可能指望程序能处理这样的情况。 exception 表示程序运行过程中可能会出现的异常情况，如果程序运行正常的话不会发生的情况。 异常表示程序运行过程中可能出现的非正常状态。运行时异常表示虚拟机的通常操作中可能遇到的异常,是一种常见运行错误，比如说 NullPointerException、IndexOutOfBoundsException、NumberFormatException、ClassCastException、IllegalArgumentException，这类异常的话 Java 虚拟机并不要求声明抛出或者捕获。而对于一般异常 Java 编译器要求方法必须声明抛出或者捕获，常见的这类异常有IOException、SQLException、InternetedException。 int 和 Integer 有什么区别，Integer 的值缓存范围Java 中有八种基本数据类型，int 就是其中一种，而每一种基本数据类型都有其对应的包装类型，两者之间的转换也称为自动装箱和自动拆箱。 对于 Integer 的值 Java 会进行缓存，值在 -128 - 127 之间的数字会进行缓存。 String、StringBuilder、StringBuffer 的理解首先 String 字符串常量，被 final 所修饰，不可被继承，StringBuilder 字符串变量，非线程安全，StringBuffer 字符串变量，线程安全，由于 String 是字符串常量，不可变，当涉及到字符串的拼接时会频繁的创建对象，所以这时需要使用 StringBuilder 和 StringBuffer 这两个类了，当然如果没有涉及到多线程的话尽量使用 StringBuilder ，它比 StringBuffer 这个类处理速度要快，当然如果涉及到多线程的话就只能使用 StringBuffer 类了。 重载和重写的区别方法的重写 Overriding 是父类与子类之间多态性的一种表现，如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写，子类重写的方法访问修饰符的限制一定要大于被重写方法的访问修饰符 (public&gt;protected&gt;default&gt;private)，重写方法一定不能抛出新的检查异常或者比被重写方法声明更加宽泛的检查型异常。 重载 Overloading 是一个类中多态性的一种体现，子类的对象使用这个方法时，将调用子类中的定义，对它而言，父类中的定义如同被”屏蔽”了。如果在一个类中定义了多个同名的方法，它们有不同的参数个数或者有不同的参数类型，则称为方法的重载 Overloading，Overloaded 的方法是可以改变返回值的类型，也可以有不同的访问修饰符，还可以抛出不同的异常。 抽象类和接口有什么区别抽象类是对根源的抽象，它表示的是这个对象是什么。同时抽象类中可以没有抽象方法，抽象类中的变量可以任意定义，对于抽象方法是要被实现的，所以不能是静态的也不能是私有的， 接口是对动作的抽象，接口表示的是这个对象能做什么。对于接口中的抽象方法默认是都是公开的，接口里定义的变量只能是公共的静态的常量，接口中一般只做方法的声明，不过在 Java 8 中可以有具体的实现，一种是由 static 修饰，另一种使用 default关键字修饰，对于 static 修饰的由接口名称直接调用，而对于 default 修饰的方法则需要对应的实现类去调用，如果一个类实现了多个接口，而且这些接口中都有相同的默认方法时，此时必须重写掉默认方法，否则编译失败。 反射的用途及实现当程序运行时，允许动态的改变程序结构或变量类型，通过反射我们可以在运行时获得程序或程序集中每一个类型成员和成员变量的信息。由于在运行时才动态加载的类或调用方法或属性，所以不需要事先（写代码的时候或编译期）知道运行对象是谁。当我们在使用 IDE 时，当我们输入一个对象名或者类名并想调用它的属性和方法时，一按 (“.”) 点号，编译器就会自动列出它的属性和方法，这里就会用到反射。 反射最重要的用途就是开发各种通用框架，很多框架（比如 Spring）都是配置化的（比如通过 XML文件配置 JavaBean，Action之类的），为了保证框架的通用性，他们可能根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射——运行时动态加载需要加载的对象。 先获得一个类的 Class 对象 : Class&lt;?&gt; klass = Class.forName(class 全类名);Class&lt;?&gt; klass = 对象.class; 或者 Class&lt;?&gt; klass = 对象.getClass();又或者 Class&lt;?&gt; klass = 类名.TYPE; 再通过拿到的 Class 对象创建实例 : Object str = klass.getInstance(); 或者 Constructor constructor = klass.getConstructor(String.class);//根据构造器创建实例Object obj = constructor.newInstance(“23333”); HTTP请求的 GET 与 POST 方式的区别 GET 方式会将请求的参数拼接在 URL 后面，会显示在地址栏中，而 POST 方式则是 放在请求体中 GET方式提交的数据最多只能有 1024 字节，POST 方式没有限制 HTTP 请求默认是 GET 方式，对于敏感的数据类型最好采用 POST 方式提交请求。 Session与Cookie区别 Cookie 和 Session 都是会话技术，Cookie 是运行在客户端，Session 是运行在服务器端，通过生成的 sessionId 来区分不同的客户，同时将 sessionId 的值通过 Cookie 返回给客户端。 Cookie 有大小限制以及浏览器在存 Cookie 的个数也有限制，Session 是没有大小限制的，和服务器的内存大小有关。 Cookie 有安全隐患，通过拦截或本地文件找得到你的 Cookie 后可以进行攻击。 Session 是保存在服务器端会存在一段时间才会消失，如果 Session 过多会增加服务器的压力。]]></content>
      <categories>
        <category>面试系列</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[我的第一篇博客]]></title>
    <url>%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[好的开始是成功的一半欢迎使用Markdown编辑器写博客本Markdown编辑器使用StackEdit修改而来，用它写博客，将会带来全新的体验哦： Markdown和扩展Markdown简洁的语法 代码块高亮 图片链接和图片上传 LaTex数学公式 UML序列图和流程图 离线写博客 导入导出Markdown文件 丰富的快捷键 快捷键 加粗 Ctrl + B 斜体 Ctrl + I 引用 Ctrl + Q 插入链接 Ctrl + L 插入代码 Ctrl + K 插入图片 Ctrl + G 提升标题 Ctrl + H 有序列表 Ctrl + O 无序列表 Ctrl + U 横线 Ctrl + R 撤销 Ctrl + Z 重做 Ctrl + Y Markdown及扩展 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— [ 维基百科 ] 使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接等，详细语法参考帮助？。 本编辑器支持 Markdown Extra , 扩展了很多好用的功能。具体请参考Github. 表格Markdown Extra 表格语法： 项目 价格 Computer $1600 Phone $12 Pipe $1 可以使用冒号来定义对齐方式： 项目 价格 数量 Computer 1600 元 5 Phone 12 元 12 Pipe 1 元 234 ###定义列表 Markdown Extra 定义列表语法：项目１项目２: 定义 A: 定义 B 项目３: 定义 C : 定义 D &gt; 定义D内容 代码块代码块语法遵循标准markdown代码，例如：12345678910@requires_authorizationdef somefunc(param1='', param2=0): '''A docstring''' if param1 &gt; param2: # interesting print 'Greater' return (param2 - param1 + 1) or Noneclass SomeClass: pass&gt;&gt;&gt; message = '''interpreter... prompt''' ###脚注生成一个脚注[^footnote]. [^footnote]: 这里是 脚注 的 内容. 目录用 [TOC]来生成目录： [TOC] 数学公式使用MathJax渲染LaTex 数学公式，详见math.stackexchange.com. 行内公式，数学公式为：$\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$。 块级公式： $$ x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$ 更多LaTex语法请参考 这儿. UML 图:可以渲染序列图： 123张三-&gt;李四: 嘿，小四儿, 写博客了没?Note right of 李四: 李四愣了一下，说：李四--&gt;张三: 忙得吐血，哪有时间写。 或者流程图： 12345678st=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 我的操作cond=&gt;condition: 确认？st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 关于 序列图 语法，参考 这儿, 关于 流程图 语法，参考 这儿. 离线写博客即使用户在没有网络的情况下，也可以通过本编辑器离线写博客（直接在曾经使用过的浏览器中输入write.blog.csdn.net/mdeditor即可。Markdown编辑器使用浏览器离线存储将内容保存在本地。 用户写博客的过程中，内容实时保存在浏览器缓存中，在用户关闭浏览器或者其它异常情况下，内容不会丢失。用户再次打开浏览器时，会显示上次用户正在编辑的没有发表的内容。 博客发表后，本地缓存将被删除。 用户可以选择 把正在写的博客保存到服务器草稿箱，即使换浏览器或者清除缓存，内容也不会丢失。 注意：虽然浏览器存储大部分时候都比较可靠，但为了您的数据安全，在联网后，请务必及时发表或者保存到服务器草稿箱。 ##浏览器兼容 目前，本编辑器对Chrome浏览器支持最为完整。建议大家使用较新版本的Chrome。 IE９以下不支持 IE９，１０，１１存在以下问题 不支持离线功能 IE9不支持文件导入导出 IE10不支持拖拽文件导入]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
  </entry>
</search>
